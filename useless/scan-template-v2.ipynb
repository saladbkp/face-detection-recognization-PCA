{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Face Recognition Scanner\n",
    "\n",
    "This notebook performs face recognition using template matching and PCA features with cosine_similarity checking."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import json\n",
    "import os\n",
    "import numpy as np\n",
    "import pickle\n",
    "import argparse\n",
    "import glob\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c549e68a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiModelFaceScanner:\n",
    "    def __init__(self):\n",
    "        \"\"\"\n",
    "        Initialize multi-model face scanner\n",
    "        \"\"\"\n",
    "        self.models = {}\n",
    "        self.face_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_frontalface_default.xml')\n",
    "        \n",
    "    def load_all_models(self):\n",
    "        \"\"\"\n",
    "        Load all available models from faces/lock_version/*/face_model.pkl\n",
    "        \"\"\"\n",
    "        model_pattern = \"faces/lock_version/*/face_model.pkl\"\n",
    "        model_paths = glob.glob(model_pattern)\n",
    "        \n",
    "        if not model_paths:\n",
    "            print(f\"No models found matching pattern: {model_pattern}\")\n",
    "            return False\n",
    "        \n",
    "        print(f\"Found {len(model_paths)} model(s):\")\n",
    "        \n",
    "        for model_path in model_paths:\n",
    "            # Extract person name from path\n",
    "            person_name = os.path.basename(os.path.dirname(model_path))\n",
    "            \n",
    "            try:\n",
    "                # Load model\n",
    "                with open(model_path, 'rb') as f:\n",
    "                    model_data = pickle.load(f)\n",
    "                \n",
    "                # Load detection data\n",
    "                detection_json_path = os.path.join(os.path.dirname(model_path), f\"{person_name}_faces_detection.json\")\n",
    "                detection_data = None\n",
    "                if os.path.exists(detection_json_path):\n",
    "                    with open(detection_json_path, 'r', encoding='utf-8') as f:\n",
    "                        detection_data = json.load(f)\n",
    "                \n",
    "                # Load template image\n",
    "                template_image = None\n",
    "                if detection_data and detection_data['faces']:\n",
    "                    first_face = detection_data['faces'][0]\n",
    "                    template_path = first_face['image_path']\n",
    "                    if os.path.exists(template_path):\n",
    "                        template_image = cv2.imread(template_path, cv2.IMREAD_GRAYSCALE)\n",
    "                \n",
    "                self.models[person_name] = {\n",
    "                    'model_data': model_data,\n",
    "                    'detection_data': detection_data,\n",
    "                    'template_image': template_image,\n",
    "                    'model_path': model_path\n",
    "                }\n",
    "                \n",
    "                face_count = len(model_data['face_features']) if model_data else 0\n",
    "                print(f\"  - {person_name}: {face_count} faces\")\n",
    "                \n",
    "            except Exception as e:\n",
    "                print(f\"  - Failed to load {person_name}: {e}\")\n",
    "        \n",
    "        print(f\"Successfully loaded {len(self.models)} model(s)\")\n",
    "        return len(self.models) > 0\n",
    "    \n",
    "    def extract_face_features(self, face_img, model_data):\n",
    "        \"\"\"\n",
    "        Extract face features using specific model\n",
    "        \"\"\"\n",
    "        if len(face_img.shape) == 3:\n",
    "            gray = cv2.cvtColor(face_img, cv2.COLOR_BGR2GRAY)\n",
    "        else:\n",
    "            gray = face_img\n",
    "        \n",
    "        resized = cv2.resize(gray, (64, 64))\n",
    "        flattened = resized.flatten().reshape(1, -1)\n",
    "        \n",
    "        scaled = model_data['scaler'].transform(flattened)\n",
    "        features = model_data['pca'].transform(scaled)\n",
    "        \n",
    "        return features[0]\n",
    "    \n",
    "    def recognize_face_with_model(self, face_features, model_data, threshold=0.7):\n",
    "        \"\"\"\n",
    "        Recognize face using specific model\n",
    "        \"\"\"\n",
    "        similarities = cosine_similarity([face_features], model_data['face_features'])[0]\n",
    "        max_idx = np.argmax(similarities)\n",
    "        max_similarity = similarities[max_idx]\n",
    "        \n",
    "        if max_similarity >= threshold:\n",
    "            person_id = model_data['face_labels'][max_idx]\n",
    "            person_name = \"unknown\"\n",
    "            for name, pid in model_data['person_id_map'].items():\n",
    "                if pid == person_id:\n",
    "                    person_name = name\n",
    "                    break\n",
    "            return person_id, person_name, max_similarity\n",
    "        else:\n",
    "            return -1, \"unknown\", max_similarity\n",
    "    \n",
    "    def recognize_face_all_models(self, face_img, threshold=0.7):\n",
    "        \"\"\"\n",
    "        Recognize face using all loaded models and return best match\n",
    "        \"\"\"\n",
    "        best_result = None\n",
    "        best_confidence = 0.0\n",
    "        best_person = \"unknown\"\n",
    "        \n",
    "        for person_name, model_info in self.models.items():\n",
    "            model_data = model_info['model_data']\n",
    "            if model_data is None:\n",
    "                continue\n",
    "            \n",
    "            try:\n",
    "                features = self.extract_face_features(face_img, model_data)\n",
    "                person_id, recognized_name, confidence = self.recognize_face_with_model(features, model_data, threshold)\n",
    "                \n",
    "                if confidence > best_confidence:\n",
    "                    best_confidence = confidence\n",
    "                    best_person = recognized_name if recognized_name != \"unknown\" else person_name\n",
    "                    best_result = (person_id, best_person, confidence)\n",
    "            \n",
    "            except Exception as e:\n",
    "                print(f\"Error recognizing with model {person_name}: {e}\")\n",
    "                continue\n",
    "        \n",
    "        if best_result:\n",
    "            return best_result\n",
    "        else:\n",
    "            return -1, \"unknown\", 0.0\n",
    "    \n",
    "    def process_live_camera(self, show_preview=True):\n",
    "        \"\"\"\n",
    "        Process live camera for real-time face recognition using all models\n",
    "        \"\"\"\n",
    "        if not self.models:\n",
    "            print(\"Error: No models loaded!\")\n",
    "            return\n",
    "        \n",
    "        cap = cv2.VideoCapture(0)\n",
    "        if not cap.isOpened():\n",
    "            print(\"Error: Could not open camera\")\n",
    "            return\n",
    "        \n",
    "        print(\"Starting live face recognition with multiple models...\")\n",
    "        print(\"Press 'q' to quit\")\n",
    "        \n",
    "        frame_count = 0\n",
    "        recognition_results = []\n",
    "        \n",
    "        while True:\n",
    "            ret, frame = cap.read()\n",
    "            if not ret:\n",
    "                print(\"Error: Failed to read frame from camera\")\n",
    "                break\n",
    "            \n",
    "            gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "            \n",
    "            # Detect faces using Haar cascade\n",
    "            faces = self.face_cascade.detectMultiScale(gray, 1.1, 4)\n",
    "            \n",
    "            for (x, y, w, h) in faces:\n",
    "                # Extract face image\n",
    "                face_img = frame[y:y+h, x:x+w]\n",
    "                \n",
    "                # Recognize face using all models\n",
    "                person_id, person_name, confidence = self.recognize_face_all_models(face_img)\n",
    "                \n",
    "                # Draw result\n",
    "                color = (0, 255, 0) if person_name != \"unknown\" else (0, 0, 255)\n",
    "                cv2.rectangle(frame, (x, y), (x + w, y + h), color, 2)\n",
    "                \n",
    "                # Add label\n",
    "                label = f\"{person_name} ({confidence:.2f})\"\n",
    "                cv2.putText(frame, label, (x, y - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.6, color, 2)\n",
    "                \n",
    "                # Record result\n",
    "                result = {\n",
    "                    'frame_number': frame_count,\n",
    "                    'person_name': person_name,\n",
    "                    'confidence': confidence,\n",
    "                    'x': x, 'y': y, 'width': w, 'height': h\n",
    "                }\n",
    "                recognition_results.append(result)\n",
    "            \n",
    "            # Show preview\n",
    "            if show_preview:\n",
    "                cv2.imshow('Multi-Model Face Recognition', frame)\n",
    "                if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "                    break\n",
    "            \n",
    "            frame_count += 1\n",
    "        \n",
    "        # Clean up resources\n",
    "        cap.release()\n",
    "        cv2.destroyAllWindows()\n",
    "        \n",
    "        print(\"\\nLive recognition stopped!\")\n",
    "        return recognition_results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## User Input Section\n",
    "\n",
    "Please provide the required information:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Choose input mode:\n",
      "1. Video file\n",
      "2. Live camera\n",
      "Person name: Joseph_Lai\n",
      "Mode: Video file\n",
      "Video input: Joseph_Lai.mp4\n"
     ]
    }
   ],
   "source": [
    "# Get user input\n",
    "person_name = input(\"Enter person name: \")\n",
    "\n",
    "# Choose input mode\n",
    "print(\"\\nChoose input mode:\")\n",
    "print(\"1. Video file\")\n",
    "print(\"2. Live camera\")\n",
    "mode_choice = input(\"Enter your choice (1 or 2): \")\n",
    "\n",
    "is_live_mode = mode_choice == '2'\n",
    "video_input = None\n",
    "\n",
    "if not is_live_mode:\n",
    "    video_input = input(\"Enter video file path: \")\n",
    "\n",
    "print(f\"Person name: {person_name}\")\n",
    "print(f\"Mode: {'Live camera' if is_live_mode else 'Video file'}\")\n",
    "if video_input:\n",
    "    print(f\"Video input: {video_input}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model path: faces/lock_version/Joseph_Lai/face_model.pkl\n",
      "Detection JSON: faces/lock_version/Joseph_Lai/Joseph_Lai_faces_detection.json\n",
      "Output video: faces/lock_version/Joseph_Lai/recognition_output.mp4\n",
      "Video input: videos/Joseph_Lai.mp4\n"
     ]
    }
   ],
   "source": [
    "# Configure paths based on person name\n",
    "base_dir = f\"faces/lock_version/{person_name}\"\n",
    "model_path = f\"{base_dir}/face_model.pkl\"\n",
    "detection_json_path = f\"{base_dir}/{person_name}_faces_detection.json\"\n",
    "output_video = f\"{base_dir}/recognition_output.mp4\"\n",
    "video_input = f\"videos/{video_input}\"\n",
    "\n",
    "print(f\"Model path: {model_path}\")\n",
    "print(f\"Detection JSON: {detection_json_path}\")\n",
    "print(f\"Output video: {output_video}\")\n",
    "print(f\"Video input: {video_input}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model file found.\n",
      "Detection JSON found.\n",
      "Video file found.\n"
     ]
    }
   ],
   "source": [
    "# Check necessary files\n",
    "if not os.path.exists(model_path):\n",
    "    print(f\"Error: Model file {model_path} not found!\")\n",
    "    print(\"Please run train-v2.py first to train the model.\")\n",
    "else:\n",
    "    print(\"Model file found.\")\n",
    "\n",
    "if not os.path.exists(detection_json_path):\n",
    "    print(f\"Error: Detection JSON {detection_json_path} not found!\")\n",
    "    print(\"Please run detection-v2.py first to generate detection data.\")\n",
    "else:\n",
    "    print(\"Detection JSON found.\")\n",
    "\n",
    "if not is_live_mode and video_input and not os.path.exists(video_input):\n",
    "    print(f\"Error: Video file {video_input} not found!\")\n",
    "elif not is_live_mode and video_input:\n",
    "    print(\"Video file found.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PCA model loaded: 77 faces, 1 persons\n",
      "Detection data loaded: 77 detected faces\n",
      "Template image loaded: faces/lock_version/Joseph_Lai\\face_000000_frame_000000.jpg\n",
      "Model and data loaded successfully!\n"
     ]
    }
   ],
   "source": [
    "# Create scanner and load model\n",
    "scanner = MultiModelFaceScanner()\n",
    "\n",
    "# Load all available models\n",
    "if not scanner.load_all_models():\n",
    "    print(\"Failed to load any models!\")\n",
    "    print(\"Please run train-v2.py first to train models.\")\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Starting face recognition...\n",
      "Press 'q' to quit preview window\n",
      "Processing video: videos/Joseph_Lai.mp4\n",
      "Resolution: 480x848, FPS: 30.0, Total frames: 131\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress: 76.3% (100/131 frames)\n",
      "\n",
      "Recognition completed!\n",
      "Total recognitions: 109\n",
      "Results saved to: faces/lock_version/Joseph_Lai/recognition_results.json\n",
      "Output video saved to: faces/lock_version/Joseph_Lai/recognition_output.mp4\n",
      "\n",
      "Recognition summary:\n",
      "  Joseph_Lai: 87 detections\n",
      "  unknown: 22 detections\n"
     ]
    }
   ],
   "source": [
    "# Process video or live camera\n",
    "if is_live_mode:\n",
    "    print(\"\\nStarting live face recognition...\")\n",
    "    print(\"Press 'q' to quit\")\n",
    "    results = scanner.process_live_camera(show_preview=True)\n",
    "else:\n",
    "    print(\"\\nStarting video face recognition...\")\n",
    "    print(\"Press 'q' to quit preview window\")\n",
    "    # Note: Video processing for MultiModelFaceScanner not implemented yet\n",
    "    print(\"Video processing with multi-model scanner not implemented yet.\")\n",
    "    print(\"Please use --live mode for now.\")\n",
    "    return\n",
    "    \n",
    "if results:\n",
    "    print(f\"\\nRecognition summary:\")\n",
    "    # Count recognition results\n",
    "    person_counts = {}\n",
    "    for result in results:\n",
    "        name = result['person_name']\n",
    "        person_counts[name] = person_counts.get(name, 0) + 1\n",
    "    \n",
    "    for name, count in person_counts.items():\n",
    "        print(f\"  {name}: {count} detections\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1802d58",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
