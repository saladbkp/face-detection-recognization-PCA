import cv2
import json
import os
import numpy as np
import pickle
import argparse
from sklearn.decomposition import PCA
from sklearn.preprocessing import StandardScaler
from datetime import datetime

class FaceTrainer:
    def __init__(self, n_components=50):
        """
        Initialize face trainer
        
        Args:
            n_components: Number of features after PCA dimensionality reduction
        """
        self.n_components = n_components
        self.pca = PCA(n_components=n_components)
        self.scaler = StandardScaler()
        self.face_features = []
        self.face_labels = []
        self.face_info = []
        self.is_trained = False
        
    def load_face_images(self, json_path, face_dir):
        """
        Load face data from JSON file and image directory
        
        Args:
            json_path: JSON file path generated by detection-v2.py
            face_dir: Face images directory
        """
        print(f"Loading face data from {json_path}")
        
        # Read JSON data
        with open(json_path, 'r', encoding='utf-8') as f:
            data = json.load(f)
        
        faces_data = data['faces']
        print(f"Found {len(faces_data)} faces in JSON")
        
        face_images = []
        valid_faces = []
        
        for i, face_info in enumerate(faces_data):
            image_path = face_info['image_path']
            
            # Check if image file exists
            if not os.path.exists(image_path):
                print(f"Warning: Image {image_path} not found, skipping...")
                continue
            
            # Read and preprocess image
            img = cv2.imread(image_path)
            if img is None:
                print(f"Warning: Could not read image {image_path}, skipping...")
                continue
            
            # Convert to grayscale and resize
            gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)
            resized = cv2.resize(gray, (64, 64))  # Uniform size
            
            face_images.append(resized.flatten())  # Flatten to 1D vector
            valid_faces.append(face_info)
        
        print(f"Successfully loaded {len(face_images)} face images")
        
        self.face_images = np.array(face_images)
        self.face_info = valid_faces
        
        return len(face_images)
    
    def assign_labels_interactive(self, person_name):
        """
        Assign labels to faces - simplified version using provided person name
        
        Args:
            person_name: Name of the person for labeling all faces
        """
        print("\n=== Face Labeling ===")
        print(f"Found {len(self.face_info)} faces to label.")
        print(f"Using person name: {person_name}")
        print(f"Labeling all {len(self.face_info)} faces as '{person_name}'...")
        
        # Assign same label to all faces
        labels = []
        person_id_map = {person_name: 0}
        
        for i, face_info in enumerate(self.face_info):
            labels.append(0)  # All faces use ID 0
            
            # Update face_info
            self.face_info[i]['person_name'] = person_name
            self.face_info[i]['person_id'] = 0
        
        print(f"\nLabeling completed!")
        print(f"Total persons identified: 1")
        print(f"  {person_name} (ID: 0): {len(labels)} faces")
        
        self.face_labels = np.array(labels)
        self.person_id_map = person_id_map
        
        return labels
    
    def train_pca_model(self):
        """
        Train face feature model using PCA
        """
        if len(self.face_images) == 0:
            print("Error: No face images loaded!")
            return False
        
        if len(self.face_labels) == 0:
            print("Error: No face labels assigned!")
            return False
        
        print(f"\nTraining PCA model with {len(self.face_images)} faces...")
        print(f"Original feature dimension: {self.face_images.shape[1]}")
        print(f"Reducing to {self.n_components} components")
        
        # Standardize features
        scaled_features = self.scaler.fit_transform(self.face_images)
        
        # PCA dimensionality reduction
        pca_features = self.pca.fit_transform(scaled_features)
        
        print(f"PCA explained variance ratio: {self.pca.explained_variance_ratio_.sum():.3f}")
        print(f"Reduced feature dimension: {pca_features.shape[1]}")
        
        self.face_features = pca_features
        self.is_trained = True
        
        return True
    
    def save_model(self, model_path):
        """
        Save trained model
        
        Args:
            model_path: Model save path
        """
        if not self.is_trained:
            print("Error: Model not trained yet!")
            return False
        
        model_data = {
            'pca': self.pca,
            'scaler': self.scaler,
            'face_features': self.face_features,
            'face_labels': self.face_labels,
            'face_info': self.face_info,
            'person_id_map': self.person_id_map,
            'n_components': self.n_components,
            'training_date': datetime.now().isoformat()
        }
        
        with open(model_path, 'wb') as f:
            pickle.dump(model_data, f)
        
        print(f"Model saved to {model_path}")
        return True
    
    def load_model(self, model_path):
        """
        Load trained model
        
        Args:
            model_path: Model file path
        """
        if not os.path.exists(model_path):
            print(f"Error: Model file {model_path} not found!")
            return False
        
        with open(model_path, 'rb') as f:
            model_data = pickle.load(f)
        
        self.pca = model_data['pca']
        self.scaler = model_data['scaler']
        self.face_features = model_data['face_features']
        self.face_labels = model_data['face_labels']
        self.face_info = model_data['face_info']
        self.person_id_map = model_data['person_id_map']
        self.n_components = model_data['n_components']
        self.is_trained = True
        
        print(f"Model loaded from {model_path}")
        print(f"Training date: {model_data.get('training_date', 'Unknown')}")
        print(f"Total faces: {len(self.face_features)}")
        print(f"Total persons: {len(self.person_id_map)}")
        
        return True

def main():
    # Parse command line arguments
    parser = argparse.ArgumentParser(description='Train face recognition model using PCA')
    parser.add_argument('--person', required=True, help='Person name for training model')
    args = parser.parse_args()
    
    # Configure paths based on person name
    person_name = args.person
    json_path = f"faces/lock_version/{person_name}/{person_name}_faces_detection.json"
    face_dir = f"faces/lock_version/{person_name}"
    model_path = f"faces/lock_version/{person_name}/face_model.pkl"
    
    # Check input file
    if not os.path.exists(json_path):
        print(f"Error: JSON file {json_path} not found!")
        print("Please run detection-v2.py first to generate face data.")
        return
    
    # Create trainer
    trainer = FaceTrainer(n_components=50)
    
    # Load face images
    num_faces = trainer.load_face_images(json_path, face_dir)
    if num_faces == 0:
        print("No valid face images found!")
        return
    
    # Assign labels to faces
    labels = trainer.assign_labels_interactive(person_name)
    if len(labels) == 0:
        print("No faces labeled, training cancelled.")
        return
    
    # Train PCA model
    if trainer.train_pca_model():
        # Save model
        trainer.save_model(model_path)
        print(f"\nTraining completed successfully!")
        print(f"Model saved to: {model_path}")
    else:
        print("Training failed!")

if __name__ == "__main__":
    main()