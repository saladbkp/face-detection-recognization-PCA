{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Face Training Pipeline\n",
    "\n",
    "This notebook trains a face recognition model using PCA with eigenfaces support."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import json\n",
    "import os\n",
    "import numpy as np\n",
    "import pickle\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FaceTrainer:\n",
    "    def __init__(self, n_components=50):\n",
    "        \"\"\"\n",
    "        Initialize face trainer with eigenfaces support\n",
    "        \n",
    "        Args:\n",
    "            n_components: Number of features after PCA dimensionality reduction\n",
    "        \"\"\"\n",
    "        self.n_components = n_components\n",
    "        self.pca = PCA(n_components=n_components)\n",
    "        self.scaler = StandardScaler()\n",
    "        self.face_features = []\n",
    "        self.face_labels = []\n",
    "        self.face_info = []\n",
    "        self.is_trained = False\n",
    "        self.mean_face = None\n",
    "        self.eigenfaces = None\n",
    "        self.face_shape = (64, 64)  # Standard face image size\n",
    "        \n",
    "    def load_face_images(self, json_path, face_dir):\n",
    "        \"\"\"\n",
    "        Load face data from JSON file and image directory\n",
    "        \n",
    "        Args:\n",
    "            json_path: JSON file path generated by detection-v2.py\n",
    "            face_dir: Face images directory\n",
    "        \"\"\"\n",
    "        print(f\"Loading face data from {json_path}\")\n",
    "        \n",
    "        # Read JSON data\n",
    "        with open(json_path, 'r', encoding='utf-8') as f:\n",
    "            data = json.load(f)\n",
    "        \n",
    "        faces_data = data['faces']\n",
    "        print(f\"Found {len(faces_data)} faces in JSON\")\n",
    "        \n",
    "        face_images = []\n",
    "        valid_faces = []\n",
    "        \n",
    "        for i, face_info in enumerate(faces_data):\n",
    "            image_path = face_info['image_path']\n",
    "            \n",
    "            # Check if image file exists\n",
    "            if not os.path.exists(image_path):\n",
    "                print(f\"Warning: Image {image_path} not found, skipping...\")\n",
    "                continue\n",
    "            \n",
    "            # Read and preprocess image\n",
    "            img = cv2.imread(image_path)\n",
    "            if img is None:\n",
    "                print(f\"Warning: Could not read image {image_path}, skipping...\")\n",
    "                continue\n",
    "            \n",
    "            # Convert to grayscale and resize\n",
    "            gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "            resized = cv2.resize(gray, (64, 64))  # Uniform size\n",
    "            \n",
    "            face_images.append(resized.flatten())  # Flatten to 1D vector\n",
    "            valid_faces.append(face_info)\n",
    "        \n",
    "        print(f\"Successfully loaded {len(face_images)} face images\")\n",
    "        \n",
    "        self.face_images = np.array(face_images)\n",
    "        self.face_info = valid_faces\n",
    "        \n",
    "        return len(face_images)\n",
    "    \n",
    "    def assign_labels_interactive(self, person_name):\n",
    "        \"\"\"\n",
    "        Assign labels to faces - simplified version using provided person name\n",
    "        \n",
    "        Args:\n",
    "            person_name: Name of the person for labeling all faces\n",
    "        \"\"\"\n",
    "        print(\"\\n=== Face Labeling ===\")\n",
    "        print(f\"Found {len(self.face_info)} faces to label.\")\n",
    "        print(f\"Using person name: {person_name}\")\n",
    "        print(f\"Labeling all {len(self.face_info)} faces as '{person_name}'...\")\n",
    "        \n",
    "        # Assign same label to all faces\n",
    "        labels = []\n",
    "        person_id_map = {person_name: 0}\n",
    "        \n",
    "        for i, face_info in enumerate(self.face_info):\n",
    "            labels.append(0)  # All faces use ID 0\n",
    "            \n",
    "            # Update face_info\n",
    "            self.face_info[i]['person_name'] = person_name\n",
    "            self.face_info[i]['person_id'] = 0\n",
    "        \n",
    "        print(f\"\\nLabeling completed!\")\n",
    "        print(f\"Total persons identified: 1\")\n",
    "        print(f\"  {person_name} (ID: 0): {len(labels)} faces\")\n",
    "        \n",
    "        self.face_labels = np.array(labels)\n",
    "        self.person_id_map = person_id_map\n",
    "        \n",
    "        return labels\n",
    "    \n",
    "    def train_pca_model(self):\n",
    "        \"\"\"\n",
    "        Train face feature model using PCA and generate eigenfaces\n",
    "        \"\"\"\n",
    "        if len(self.face_images) == 0:\n",
    "            print(\"Error: No face images loaded!\")\n",
    "            return False\n",
    "        \n",
    "        if len(self.face_labels) == 0:\n",
    "            print(\"Error: No face labels assigned!\")\n",
    "            return False\n",
    "        \n",
    "        print(f\"\\nTraining PCA model with {len(self.face_images)} faces...\")\n",
    "        print(f\"Original feature dimension: {self.face_images.shape[1]}\")\n",
    "        print(f\"Reducing to {self.n_components} components\")\n",
    "        \n",
    "        # Calculate mean face\n",
    "        self.mean_face = np.mean(self.face_images, axis=0)\n",
    "        print(f\"Mean face calculated with shape: {self.mean_face.shape}\")\n",
    "        \n",
    "        # Standardize features\n",
    "        scaled_features = self.scaler.fit_transform(self.face_images)\n",
    "        \n",
    "        # PCA dimensionality reduction\n",
    "        pca_features = self.pca.fit_transform(scaled_features)\n",
    "        \n",
    "        # Extract eigenfaces (principal components)\n",
    "        self.eigenfaces = self.pca.components_\n",
    "        print(f\"Generated {len(self.eigenfaces)} eigenfaces\")\n",
    "        \n",
    "        print(f\"PCA explained variance ratio: {self.pca.explained_variance_ratio_.sum():.3f}\")\n",
    "        print(f\"Reduced feature dimension: {pca_features.shape[1]}\")\n",
    "        \n",
    "        self.face_features = pca_features\n",
    "        self.is_trained = True\n",
    "        \n",
    "        return True\n",
    "    \n",
    "    def save_eigenfaces(self, output_dir, person_name):\n",
    "        \"\"\"\n",
    "        Save eigenfaces and mean face as images\n",
    "        \n",
    "        Args:\n",
    "            output_dir: Output directory for saving images\n",
    "            person_name: Person name for file naming\n",
    "        \"\"\"\n",
    "        if not self.is_trained:\n",
    "            print(\"Error: Model not trained yet!\")\n",
    "            return False\n",
    "        \n",
    "        # Create output directory if it doesn't exist\n",
    "        os.makedirs(output_dir, exist_ok=True)\n",
    "        \n",
    "        # Save mean face\n",
    "        mean_face_img = self.mean_face.reshape(self.face_shape)\n",
    "        mean_face_normalized = cv2.normalize(mean_face_img, None, 0, 255, cv2.NORM_MINMAX, dtype=cv2.CV_8U)\n",
    "        mean_face_path = os.path.join(output_dir, f\"{person_name}_mean_face.jpg\")\n",
    "        cv2.imwrite(mean_face_path, mean_face_normalized)\n",
    "        print(f\"Mean face saved to: {mean_face_path}\")\n",
    "        \n",
    "        # Save top eigenfaces\n",
    "        num_eigenfaces_to_save = min(10, len(self.eigenfaces))\n",
    "        for i in range(num_eigenfaces_to_save):\n",
    "            eigenface = self.eigenfaces[i].reshape(self.face_shape)\n",
    "            # Normalize eigenface for visualization\n",
    "            eigenface_normalized = cv2.normalize(eigenface, None, 0, 255, cv2.NORM_MINMAX, dtype=cv2.CV_8U)\n",
    "            eigenface_path = os.path.join(output_dir, f\"{person_name}_eigenface_{i+1:02d}.jpg\")\n",
    "            cv2.imwrite(eigenface_path, eigenface_normalized)\n",
    "        \n",
    "        print(f\"Saved {num_eigenfaces_to_save} eigenfaces to {output_dir}\")\n",
    "        \n",
    "        # Save model information\n",
    "        model_info = {\n",
    "            'person_name': person_name,\n",
    "            'training_date': datetime.now().isoformat(),\n",
    "            'total_faces': len(self.face_images),\n",
    "            'n_components': self.n_components,\n",
    "            'explained_variance_ratio': float(self.pca.explained_variance_ratio_.sum()),\n",
    "            'face_shape': self.face_shape,\n",
    "            'eigenfaces_saved': num_eigenfaces_to_save\n",
    "        }\n",
    "        \n",
    "        info_path = os.path.join(output_dir, f\"{person_name}_model_info.json\")\n",
    "        with open(info_path, 'w', encoding='utf-8') as f:\n",
    "            json.dump(model_info, f, indent=2, ensure_ascii=False)\n",
    "        \n",
    "        print(f\"Model information saved to: {info_path}\")\n",
    "        return True\n",
    "    \n",
    "    def save_model(self, model_path):\n",
    "        \"\"\"\n",
    "        Save trained model with eigenfaces support\n",
    "        \n",
    "        Args:\n",
    "            model_path: Model save path\n",
    "        \"\"\"\n",
    "        if not self.is_trained:\n",
    "            print(\"Error: Model not trained yet!\")\n",
    "            return False\n",
    "        \n",
    "        model_data = {\n",
    "            'pca': self.pca,\n",
    "            'scaler': self.scaler,\n",
    "            'face_features': self.face_features,\n",
    "            'face_labels': self.face_labels,\n",
    "            'face_info': self.face_info,\n",
    "            'person_id_map': self.person_id_map,\n",
    "            'n_components': self.n_components,\n",
    "            'mean_face': self.mean_face,\n",
    "            'eigenfaces': self.eigenfaces,\n",
    "            'face_shape': self.face_shape,\n",
    "            'training_date': datetime.now().isoformat()\n",
    "        }\n",
    "        \n",
    "        with open(model_path, 'wb') as f:\n",
    "            pickle.dump(model_data, f)\n",
    "        \n",
    "        print(f\"Model saved to {model_path}\")\n",
    "        return True\n",
    "    \n",
    "    def load_model(self, model_path):\n",
    "        \"\"\"\n",
    "        Load trained model with eigenfaces support\n",
    "        \n",
    "        Args:\n",
    "            model_path: Model file path\n",
    "        \"\"\"\n",
    "        if not os.path.exists(model_path):\n",
    "            print(f\"Error: Model file {model_path} not found!\")\n",
    "            return False\n",
    "        \n",
    "        with open(model_path, 'rb') as f:\n",
    "            model_data = pickle.load(f)\n",
    "        \n",
    "        self.pca = model_data['pca']\n",
    "        self.scaler = model_data['scaler']\n",
    "        self.face_features = model_data['face_features']\n",
    "        self.face_labels = model_data['face_labels']\n",
    "        self.face_info = model_data['face_info']\n",
    "        self.person_id_map = model_data['person_id_map']\n",
    "        self.n_components = model_data['n_components']\n",
    "        \n",
    "        # Load eigenfaces data if available\n",
    "        self.mean_face = model_data.get('mean_face', None)\n",
    "        self.eigenfaces = model_data.get('eigenfaces', None)\n",
    "        self.face_shape = model_data.get('face_shape', (64, 64))\n",
    "        \n",
    "        self.is_trained = True\n",
    "        \n",
    "        print(f\"Model loaded from {model_path}\")\n",
    "        print(f\"Training date: {model_data.get('training_date', 'Unknown')}\")\n",
    "        print(f\"Total faces: {len(self.face_features)}\")\n",
    "        print(f\"Total persons: {len(self.person_id_map)}\")\n",
    "        if self.eigenfaces is not None:\n",
    "            print(f\"Eigenfaces loaded: {len(self.eigenfaces)}\")\n",
    "        \n",
    "        return True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## User Input Section\n",
    "\n",
    "Please provide the required information:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Person name: Joseph_Lai\n",
      "JSON path: faces/lock_version/Joseph_Lai/Joseph_Lai_faces_detection.json\n",
      "Face directory: faces/lock_version/Joseph_Lai\n",
      "Model output: faces/lock_version/Joseph_Lai/face_model.pkl\n"
     ]
    }
   ],
   "source": [
    "# Get user input\n",
    "person_name = input(\"Enter person name for training: \")\n",
    "\n",
    "# Configure paths based on person name\n",
    "json_path = f\"faces/lock_version/{person_name}/{person_name}_faces_detection.json\"\n",
    "face_dir = f\"faces/lock_version/{person_name}\"\n",
    "model_path = f\"faces/lock_version/{person_name}/face_model.pkl\"\n",
    "\n",
    "print(f\"Person name: {person_name}\")\n",
    "print(f\"JSON path: {json_path}\")\n",
    "print(f\"Face directory: {face_dir}\")\n",
    "print(f\"Model output: {model_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "JSON file found, proceeding with training...\n"
     ]
    }
   ],
   "source": [
    "# Check input file\n",
    "if not os.path.exists(json_path):\n",
    "    print(f\"Error: JSON file {json_path} not found!\")\n",
    "    print(\"Please run detection-v2.py first to generate face data.\")\n",
    "else:\n",
    "    print(\"JSON file found, proceeding with training...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading face data from faces/lock_version/Joseph_Lai/Joseph_Lai_faces_detection.json\n",
      "Found 77 faces in JSON\n",
      "Successfully loaded 77 face images\n",
      "Loaded 77 face images successfully.\n"
     ]
    }
   ],
   "source": [
    "# Create trainer\n",
    "trainer = FaceTrainer(n_components=50)\n",
    "\n",
    "# Load face images\n",
    "num_faces = trainer.load_face_images(json_path, face_dir)\n",
    "if num_faces == 0:\n",
    "    print(\"No valid face images found!\")\n",
    "else:\n",
    "    print(f\"Loaded {num_faces} face images successfully.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Face Labeling ===\n",
      "Found 77 faces to label.\n",
      "Using person name: Joseph_Lai\n",
      "Labeling all 77 faces as 'Joseph_Lai'...\n",
      "\n",
      "Labeling completed!\n",
      "Total persons identified: 1\n",
      "  Joseph_Lai (ID: 0): 77 faces\n",
      "Successfully labeled 77 faces.\n"
     ]
    }
   ],
   "source": [
    "# Assign labels to faces\n",
    "if num_faces > 0:\n",
    "    labels = trainer.assign_labels_interactive(person_name)\n",
    "    if len(labels) == 0:\n",
    "        print(\"No faces labeled, training cancelled.\")\n",
    "    else:\n",
    "        print(f\"Successfully labeled {len(labels)} faces.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training PCA model with 77 faces...\n",
      "Original feature dimension: 4096\n",
      "Reducing to 50 components\n",
      "Mean face calculated with shape: (4096,)\n",
      "Generated 50 eigenfaces\n",
      "PCA explained variance ratio: 0.990\n",
      "Reduced feature dimension: 50\n",
      "Mean face saved to: faces/lock_version/Joseph_Lai\\Joseph_Lai_mean_face.jpg\n",
      "Saved 10 eigenfaces to faces/lock_version/Joseph_Lai\n",
      "Model information saved to: faces/lock_version/Joseph_Lai\\Joseph_Lai_model_info.json\n",
      "Model saved to faces/lock_version/Joseph_Lai/face_model.pkl\n",
      "\n",
      "Training completed successfully!\n",
      "Model saved to: faces/lock_version/Joseph_Lai/face_model.pkl\n",
      "Eigenfaces and mean face saved to: faces/lock_version/Joseph_Lai\n"
     ]
    }
   ],
   "source": [
    "# Train PCA model\n",
    "if num_faces > 0 and len(labels) > 0:\n",
    "    if trainer.train_pca_model():\n",
    "        # Save eigenfaces as images\n",
    "        trainer.save_eigenfaces(face_dir, person_name)\n",
    "        \n",
    "        # Save model\n",
    "        trainer.save_model(model_path)\n",
    "        print(f\"\\nTraining completed successfully!\")\n",
    "        print(f\"Model saved to: {model_path}\")\n",
    "        print(f\"Eigenfaces and mean face saved to: {face_dir}\")\n",
    "    else:\n",
    "        print(\"Training failed!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de154f60",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
