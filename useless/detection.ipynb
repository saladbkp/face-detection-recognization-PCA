{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "332a66ab",
   "metadata": {},
   "source": [
    "# Face Detection Pipeline\n",
    "\n",
    "This notebook detects faces in video saves face images and position data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "08162707",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import json\n",
    "import os\n",
    "import numpy as np\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b867419f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect_faces_and_save_data(video_path, output_face_dir, output_json_path):\n",
    "    \"\"\"\n",
    "    Detect faces in video using Haarcascade and save face images and position data\n",
    "    \n",
    "    Args:\n",
    "        video_path: Input video path\n",
    "        output_face_dir: Directory to save face images\n",
    "        output_json_path: Path to save JSON data\n",
    "    \"\"\"\n",
    "    # Initialize face detector\n",
    "    face_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_frontalface_default.xml')\n",
    "    \n",
    "    # Create output directory\n",
    "    if not os.path.exists(output_face_dir):\n",
    "        os.makedirs(output_face_dir)\n",
    "    \n",
    "    # Open video\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "    if not cap.isOpened():\n",
    "        print(f\"Error: Could not open video {video_path}\")\n",
    "        return\n",
    "    \n",
    "    # Get video information\n",
    "    fps = cap.get(cv2.CAP_PROP_FPS)\n",
    "    total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "    \n",
    "    print(f\"Processing video: {video_path}\")\n",
    "    print(f\"Total frames: {total_frames}, FPS: {fps}\")\n",
    "    \n",
    "    frame_count = 0\n",
    "    all_face_data = []\n",
    "    face_id = 0\n",
    "    \n",
    "    while True:\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "        \n",
    "        # Convert to grayscale\n",
    "        gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "        \n",
    "        # Detect faces\n",
    "        faces = face_cascade.detectMultiScale(\n",
    "            gray,\n",
    "            scaleFactor=1.1,\n",
    "            minNeighbors=5,\n",
    "            minSize=(30, 30)\n",
    "        )\n",
    "        \n",
    "        # Process each detected face\n",
    "        for i, (x, y, w, h) in enumerate(faces):\n",
    "            # Extract face region\n",
    "            face_img = frame[y:y+h, x:x+w]\n",
    "            \n",
    "            # Save face image\n",
    "            face_filename = f\"face_{face_id:06d}_frame_{frame_count:06d}.jpg\"\n",
    "            face_path = os.path.join(output_face_dir, face_filename)\n",
    "            cv2.imwrite(face_path, face_img)\n",
    "            \n",
    "            # Calculate timestamp\n",
    "            timestamp = frame_count / fps if fps > 0 else 0\n",
    "            \n",
    "            # Save face data\n",
    "            face_data = {\n",
    "                \"face_id\": face_id,\n",
    "                \"frame_number\": frame_count,\n",
    "                \"timestamp\": timestamp,\n",
    "                \"x\": int(x),\n",
    "                \"y\": int(y),\n",
    "                \"width\": int(w),\n",
    "                \"height\": int(h),\n",
    "                \"center_x\": int(x + w // 2),\n",
    "                \"center_y\": int(y + h // 2),\n",
    "                \"area\": int(w * h),\n",
    "                \"image_path\": face_path,\n",
    "                \"image_filename\": face_filename\n",
    "            }\n",
    "            all_face_data.append(face_data)\n",
    "            face_id += 1\n",
    "        \n",
    "        frame_count += 1\n",
    "        \n",
    "        # Show progress\n",
    "        if frame_count % 100 == 0:\n",
    "            progress = (frame_count / total_frames) * 100\n",
    "            print(f\"Progress: {progress:.1f}% ({frame_count}/{total_frames} frames)\")\n",
    "    \n",
    "    cap.release()\n",
    "    \n",
    "    # Save JSON data\n",
    "    video_info = {\n",
    "        \"video_path\": video_path,\n",
    "        \"total_frames\": total_frames,\n",
    "        \"fps\": fps,\n",
    "        \"total_faces_detected\": len(all_face_data),\n",
    "        \"processing_date\": datetime.now().isoformat(),\n",
    "        \"faces\": all_face_data\n",
    "    }\n",
    "    \n",
    "    with open(output_json_path, 'w', encoding='utf-8') as f:\n",
    "        json.dump(video_info, f, indent=2, ensure_ascii=False)\n",
    "    \n",
    "    print(f\"\\nDetection completed!\")\n",
    "    print(f\"Total faces detected: {len(all_face_data)}\")\n",
    "    print(f\"Face images saved to: {output_face_dir}\")\n",
    "    print(f\"JSON data saved to: {output_json_path}\")\n",
    "    \n",
    "    return video_info"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bf5a71f",
   "metadata": {},
   "source": [
    "## User Input Section\n",
    "\n",
    "Please provide the required information:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "22c7a214",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Video input: Joseph_Lai.mp4\n",
      "Person name: Joseph_Lai\n",
      "Output directory: faces/lock_version/Joseph_Lai\n",
      "JSON output: faces/lock_version/Joseph_Lai/Joseph_Lai_faces_detection.json\n",
      "Video directory: videos/Joseph_Lai.mp4\n"
     ]
    }
   ],
   "source": [
    "# Get user input\n",
    "video_input = input(\"Enter video file path: \")\n",
    "person_name = input(\"Enter person name: \")\n",
    "\n",
    "# Configure paths based on person name\n",
    "output_face_directory = f\"faces/lock_version/{person_name}\"\n",
    "output_json_file = f\"faces/lock_version/{person_name}/{person_name}_faces_detection.json\"\n",
    "video_directory = f\"videos/{video_input}\"\n",
    "\n",
    "print(f\"Video input: {video_input}\")\n",
    "print(f\"Person name: {person_name}\")\n",
    "print(f\"Output directory: {output_face_directory}\")\n",
    "print(f\"JSON output: {output_json_file}\")\n",
    "print(f\"Video directory: {video_directory}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b866fe67",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing video: videos/Joseph_Lai.mp4\n",
      "Total frames: 131, FPS: 30.0\n",
      "Progress: 76.3% (100/131 frames)\n",
      "\n",
      "Detection completed!\n",
      "Total faces detected: 77\n",
      "Face images saved to: faces/lock_version/Joseph_Lai\n",
      "JSON data saved to: faces/lock_version/Joseph_Lai/Joseph_Lai_faces_detection.json\n",
      "\n",
      "Face detection pipeline completed successfully!\n"
     ]
    }
   ],
   "source": [
    "# Check if video file exists\n",
    "if not os.path.exists(video_directory):\n",
    "    print(f\"Error: Video file {video_input} not found!\")\n",
    "else:\n",
    "    # Execute face detection\n",
    "    result = detect_faces_and_save_data(video_directory, output_face_directory, output_json_file)\n",
    "    print(\"\\nFace detection pipeline completed successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e32fcd02",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
