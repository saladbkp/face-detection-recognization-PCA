{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7e951dc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import\n",
    "import cv2\n",
    "import os\n",
    "import numpy as np\n",
    "import pickle\n",
    "import json\n",
    "import argparse\n",
    "from datetime import datetime\n",
    "import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2f0f6ab4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the trained PCA model from file\n",
    "def load_pca_model(model_path):\n",
    "    try:\n",
    "        with open(model_path, 'rb') as f:\n",
    "            model_data = pickle.load(f)\n",
    "        \n",
    "        print(f\"PCA model loaded successfully from: {model_path}\")\n",
    "        print(f\"Person: {model_data['person_name']}\")\n",
    "        print(f\"Training timestamp: {model_data['training_timestamp']}\")\n",
    "        print(f\"Number of components: {model_data['n_components']}\")\n",
    "        print(f\"Face dimensions: {model_data['face_dimensions']}\")\n",
    "        \n",
    "        return model_data\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"Error loading PCA model: {str(e)}\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e9d0049f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load both dark and light PCA models\n",
    "def load_dual_pca_models(dark_model_path, light_model_path):\n",
    "    print(\"=== Loading Dual PCA Models ===\")\n",
    "    \n",
    "    dark_model = load_pca_model(dark_model_path)\n",
    "    light_model = load_pca_model(light_model_path)\n",
    "    \n",
    "    if dark_model is None or light_model is None:\n",
    "        print(\"Error: Failed to load one or both models\")\n",
    "        return None, None\n",
    "    \n",
    "    print(\"Both models loaded successfully!\")\n",
    "    return dark_model, light_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a38106aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load face templates from the faces directory\n",
    "\n",
    "def load_face_templates(faces_dir=\"faces\"):\n",
    "    templates = []\n",
    "    template_info = []\n",
    "    \n",
    "    # Get all subdirectories \n",
    "    subdirs = [d for d in os.listdir(faces_dir) if os.path.isdir(os.path.join(faces_dir, d))]\n",
    "    \n",
    "    print(f\"Loading face templates from: {faces_dir}\")\n",
    "    \n",
    "    for subdir in subdirs:\n",
    "        subdir_path = os.path.join(faces_dir, subdir)\n",
    "        # Get all .jpg files\n",
    "        jpg_files = glob.glob(os.path.join(subdir_path, \"*.jpg\"))\n",
    "        \n",
    "        print(f\"Found {len(jpg_files)} template images in {subdir}\")\n",
    "        \n",
    "        for jpg_file in jpg_files[:10]:  # Limit to first 10 templates\n",
    "            try:\n",
    "                # Load template image\n",
    "                template_img = cv2.imread(jpg_file, cv2.IMREAD_GRAYSCALE)\n",
    "                if template_img is not None:\n",
    "                    templates.append(template_img)\n",
    "                    template_info.append({\n",
    "                        'path': jpg_file,\n",
    "                        'subdir': subdir,\n",
    "                        'filename': os.path.basename(jpg_file)\n",
    "                    })\n",
    "            except Exception as e:\n",
    "                print(f\"Error loading template {jpg_file}: {str(e)}\")\n",
    "    \n",
    "    print(f\"Successfully loaded {len(templates)} face templates\")\n",
    "    return templates, template_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3b0ad7c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#     Detect faces using template matching\n",
    "\n",
    "def detect_faces_with_template(gray_frame, templates, template_info, threshold=0.7, nms_threshold=0.3):\n",
    "\n",
    "    detections = []\n",
    "    \n",
    "    # Try multiple scales for template matching\n",
    "    scales = [0.5, 0.7, 1.0, 1.3, 1.6]\n",
    "    \n",
    "    for scale in scales:\n",
    "        # Resize frame for current scale\n",
    "        if scale != 1.0:\n",
    "            scaled_frame = cv2.resize(gray_frame, None, fx=scale, fy=scale)\n",
    "        else:\n",
    "            scaled_frame = gray_frame\n",
    "        \n",
    "        for i, template in enumerate(templates):\n",
    "            # Skip if template is larger than the scaled frame\n",
    "            if template.shape[0] > scaled_frame.shape[0] or template.shape[1] > scaled_frame.shape[1]:\n",
    "                continue\n",
    "            \n",
    "            # Perform template matching\n",
    "            result = cv2.matchTemplate(scaled_frame, template, cv2.TM_CCOEFF_NORMED)\n",
    "            \n",
    "            # Find locations where matching exceeds threshold\n",
    "            locations = np.where(result >= threshold)\n",
    "            \n",
    "            for pt in zip(*locations[::-1]):\n",
    "                # Calculate bounding box\n",
    "                x = int(pt[0] / scale)\n",
    "                y = int(pt[1] / scale)\n",
    "                w = int(template.shape[1] / scale)\n",
    "                h = int(template.shape[0] / scale)\n",
    "                \n",
    "                # Store detection with confidence score\n",
    "                confidence = result[int(pt[1])][int(pt[0])]\n",
    "                detections.append((x, y, w, h, confidence))\n",
    "    \n",
    "    # Apply Non-Maximum Suppression to remove overlapping detections\n",
    "    if len(detections) > 0:\n",
    "        # Convert to format expected by cv2.dnn.NMSBoxes\n",
    "        boxes = [(x, y, w, h) for x, y, w, h, _ in detections]\n",
    "        scores = [conf for _, _, _, _, conf in detections]\n",
    "        \n",
    "        # Apply NMS\n",
    "        indices = cv2.dnn.NMSBoxes(boxes, scores, threshold, nms_threshold)\n",
    "        \n",
    "        # Filter detections based on NMS results\n",
    "        if len(indices) > 0:\n",
    "            indices = indices.flatten()\n",
    "            filtered_detections = [(detections[i][0], detections[i][1], detections[i][2], detections[i][3]) \n",
    "                                 for i in indices]\n",
    "        else:\n",
    "            filtered_detections = []\n",
    "    else:\n",
    "        filtered_detections = []\n",
    "    \n",
    "    return filtered_detections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2d40fdb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate cosine similarity between two vectors\n",
    "def cosine_similarity(vec1, vec2):\n",
    "    # Normalize vectors\n",
    "    norm1 = np.linalg.norm(vec1)\n",
    "    norm2 = np.linalg.norm(vec2)\n",
    "    \n",
    "    if norm1 == 0 or norm2 == 0:\n",
    "        return 0.0\n",
    "    \n",
    "    # Calculate cosine similarity\n",
    "    similarity = np.dot(vec1, vec2) / (norm1 * norm2)\n",
    "    return similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7396e41a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Project a face vector into the eigenface space\n",
    "def project_face_to_eigenspace(face_vector, eigenfaces, mean_face):\n",
    "    # Center the face by subtracting mean\n",
    "    centered_face = face_vector - mean_face\n",
    "    \n",
    "    # Project onto eigenfaces\n",
    "    projected_face = np.dot(centered_face, eigenfaces)\n",
    "    \n",
    "    return projected_face"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "becd0d46",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Recognize a face using the trained PCA model\n",
    "def recognize_face(face_vector, model_data, similarity_threshold=0.7):\n",
    "\n",
    "    eigenfaces = model_data['eigenfaces']\n",
    "    mean_face = model_data['mean_face']\n",
    "    projected_training_data = model_data['projected_data']\n",
    "    person_name = model_data['person_name']\n",
    "    \n",
    "    # Project the input face to eigenspace\n",
    "    projected_face = project_face_to_eigenspace(face_vector, eigenfaces, mean_face)\n",
    "    \n",
    "    # Calculate similarities with all training faces\n",
    "    similarities = []\n",
    "    for training_face in projected_training_data:\n",
    "        similarity = cosine_similarity(projected_face, training_face)\n",
    "        similarities.append(similarity)\n",
    "    \n",
    "    # Get the best match\n",
    "    max_similarity = max(similarities)\n",
    "    \n",
    "    # Check if similarity exceeds threshold\n",
    "    is_recognized = max_similarity >= similarity_threshold\n",
    "    \n",
    "    return person_name, max_similarity, is_recognized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b4ebd1b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Recognize a face using both dark and light PCA models (OR logic)\n",
    "def recognize_face_dual_model(face_vector, dark_model_data, light_model_data, similarity_threshold=0.7):\n",
    "\n",
    "    # Test with dark model\n",
    "    dark_name, dark_similarity, dark_recognized = recognize_face(\n",
    "        face_vector, dark_model_data, similarity_threshold\n",
    "    )\n",
    "    \n",
    "    # Test with light model\n",
    "    light_name, light_similarity, light_recognized = recognize_face(\n",
    "        face_vector, light_model_data, similarity_threshold\n",
    "    )\n",
    "    \n",
    "    # OR logic: recognized if either model recognizes the face\n",
    "    is_recognized = dark_recognized or light_recognized\n",
    "    \n",
    "    # Use the higher similarity as the best confidence\n",
    "    best_confidence = max(dark_similarity, light_similarity)\n",
    "    \n",
    "    # Use the person name from the model with higher similarity\n",
    "    person_name = dark_name if dark_similarity >= light_similarity else light_name\n",
    "    \n",
    "    return person_name, best_confidence, is_recognized, dark_similarity, light_similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e456a76c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#     Detect and recognize faces in a frame using template matching (single model version)\n",
    "\n",
    "def detect_and_recognize_faces(frame, templates, template_info, model_data, similarity_threshold=0.7, template_threshold=0.7):\n",
    "\n",
    "    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "    \n",
    "    # Detect faces using template matching\n",
    "    faces = detect_faces_with_template(gray, templates, template_info, template_threshold)\n",
    "    \n",
    "    results = []\n",
    "    \n",
    "    for i, (x, y, w, h) in enumerate(faces):\n",
    "        # Extract face region\n",
    "        face_roi = gray[y:y+h, x:x+w]\n",
    "        \n",
    "        # Resize face to match training data dimensions\n",
    "        face_dim = int(np.sqrt(model_data['face_dimensions']))\n",
    "        face_resized = cv2.resize(face_roi, (face_dim, face_dim))\n",
    "        \n",
    "        # Flatten face to vector\n",
    "        face_vector = face_resized.flatten().astype(np.float64)\n",
    "        \n",
    "        # Recognize face\n",
    "        person_name, confidence, is_recognized = recognize_face(\n",
    "            face_vector, model_data, similarity_threshold\n",
    "        )\n",
    "        \n",
    "        # Print similarity value for debugging\n",
    "        status = \"RECOGNIZED\" if is_recognized else \"UNKNOWN\"\n",
    "        print(f\"Face {i+1} at position ({x}, {y}, {w}x{h}): similarity={confidence:.4f}, threshold={similarity_threshold:.4f}, status={status}\")\n",
    "        \n",
    "        results.append((x, y, w, h, person_name, confidence, is_recognized))\n",
    "    \n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a47dd0ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "#     Detect and recognize faces in a frame using template matching and dual models (dark + light)\n",
    "\n",
    "def detect_and_recognize_faces_dual_model(frame, templates, template_info, dark_model_data, light_model_data, similarity_threshold=0.7, template_threshold=0.7):\n",
    "\n",
    "    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "    \n",
    "    # Detect faces using template matching\n",
    "    faces = detect_faces_with_template(gray, templates, template_info, template_threshold)\n",
    "    \n",
    "    results = []\n",
    "    \n",
    "    for i, (x, y, w, h) in enumerate(faces):\n",
    "        # Extract face region\n",
    "        face_roi = gray[y:y+h, x:x+w]\n",
    "        \n",
    "        # Resize face to match training data dimensions\n",
    "        face_dim = int(np.sqrt(dark_model_data['face_dimensions']))\n",
    "        face_resized = cv2.resize(face_roi, (face_dim, face_dim))\n",
    "        \n",
    "        # Flatten face to vector\n",
    "        face_vector = face_resized.flatten().astype(np.float64)\n",
    "        \n",
    "        # Recognize face using dual models\n",
    "        person_name, best_confidence, is_recognized, dark_similarity, light_similarity = recognize_face_dual_model(\n",
    "            face_vector, dark_model_data, light_model_data, similarity_threshold\n",
    "        )\n",
    "        \n",
    "        # Print detailed similarity values for debugging\n",
    "        status = \"RECOGNIZED\" if is_recognized else \"UNKNOWN\"\n",
    "        print(f\"Face {i+1} at position ({x}, {y}, {w}x{h}):\")\n",
    "        print(f\"  Dark model:  similarity={dark_similarity:.4f}, threshold={similarity_threshold:.4f}\")\n",
    "        print(f\"  Light model: similarity={light_similarity:.4f}, threshold={similarity_threshold:.4f}\")\n",
    "        print(f\"  Best confidence: {best_confidence:.4f}, Status: {status}\")\n",
    "        \n",
    "        results.append((x, y, w, h, person_name, best_confidence, is_recognized))\n",
    "    \n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "87acb37b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#     Draw bounding boxes and labels on detected faces\n",
    "\n",
    "def draw_face_annotations(frame, detection_results, avg_face_size=None):\n",
    "\n",
    "    annotated_frame = frame.copy()\n",
    "    \n",
    "    for (x, y, w, h, person_name, confidence, is_recognized) in detection_results:\n",
    "        # Skip detection results with confidence < 0.3 and not recognized\n",
    "        if confidence < 0.3 and not is_recognized:\n",
    "            continue\n",
    "            \n",
    "        # Dynamic face size filtering based on average size\n",
    "        if avg_face_size is not None:\n",
    "            current_face_size = (w + h) / 2\n",
    "            if current_face_size < avg_face_size * 0.5:  # Skip faces smaller than 50% of average\n",
    "                continue\n",
    "        else:\n",
    "            # Fallback to original size filtering\n",
    "            if (w + h) / 2 < 200:\n",
    "                continue\n",
    "            \n",
    "        # All face detection boxes are RED SQUARES\n",
    "        box_color = (0, 0, 255)  # Red color for all detection boxes\n",
    "        \n",
    "        # Make it a square by using the larger dimension\n",
    "        size = max(w, h)\n",
    "        # Center the square on the detected face\n",
    "        square_x = x + (w - size) // 2\n",
    "        square_y = y + (h - size) // 2\n",
    "        \n",
    "        # Draw red square bounding box\n",
    "        cv2.rectangle(annotated_frame, (square_x, square_y), (square_x + size, square_y + size), box_color, 2)\n",
    "        \n",
    "        # Choose label color based on recognition status\n",
    "        if is_recognized:\n",
    "            label_color = (255, 255, 0)  # Cyan for recognized faces\n",
    "            label = f\"{person_name} ({confidence:.2f})\"\n",
    "        else:\n",
    "            label_color = (0, 0, 255)  # Red for unknown faces\n",
    "            label = f\"Unknown ({confidence:.2f})\"\n",
    "        \n",
    "        # Draw label background\n",
    "        label_size = cv2.getTextSize(label, cv2.FONT_HERSHEY_SIMPLEX, 0.6, 2)[0]\n",
    "        cv2.rectangle(\n",
    "            annotated_frame,\n",
    "            (x, y - label_size[1] - 10),\n",
    "            (x + label_size[0], y),\n",
    "            label_color,\n",
    "            -1\n",
    "        )\n",
    "        \n",
    "        # Draw label text\n",
    "        cv2.putText(\n",
    "            annotated_frame,\n",
    "            label,\n",
    "            (x, y - 5),\n",
    "            cv2.FONT_HERSHEY_SIMPLEX,\n",
    "            0.6,\n",
    "            (255, 255, 255),\n",
    "            2\n",
    "        )\n",
    "    \n",
    "    return annotated_frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "51c5fe5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#     Process video to detect and recognize faces using template matching and dual models\n",
    "\n",
    "def process_video(input_video_path, dark_model_path, light_model_path, output_video_path, similarity_threshold=0.7, template_threshold=0.7):\n",
    "\n",
    "    # Load dual PCA models\n",
    "    dark_model_data, light_model_data = load_dual_pca_models(dark_model_path, light_model_path)\n",
    "    if dark_model_data is None or light_model_data is None:\n",
    "        return False\n",
    "    \n",
    "    # Load face templates\n",
    "    templates, template_info = load_face_templates()\n",
    "    if len(templates) == 0:\n",
    "        print(\"Error: No face templates loaded\")\n",
    "        return False\n",
    "    \n",
    "    # Open input video\n",
    "    cap = cv2.VideoCapture(input_video_path)\n",
    "    if not cap.isOpened():\n",
    "        print(f\"Error: Could not open video file {input_video_path}\")\n",
    "        return False\n",
    "    \n",
    "    # Get video properties\n",
    "    fps = int(cap.get(cv2.CAP_PROP_FPS))\n",
    "    width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "    height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "    total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "    \n",
    "    print(f\"Processing video: {input_video_path}\")\n",
    "    print(f\"Video properties: {width}x{height}, {fps} FPS, {total_frames} frames\")\n",
    "    print(f\"Using {len(templates)} face templates for detection\")\n",
    "    \n",
    "    # Initialize video writer\n",
    "    fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
    "    out = cv2.VideoWriter(output_video_path, fourcc, fps, (width, height))\n",
    "    \n",
    "    # First pass: collect face sizes for dynamic filtering\n",
    "    print(\"First pass: collecting face sizes...\")\n",
    "    face_sizes = []\n",
    "    frame_count = 0\n",
    "    \n",
    "    while True:\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "        \n",
    "        frame_count += 1\n",
    "        if frame_count % 10 == 0:  # Sample every 10th frame for efficiency\n",
    "            gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "            faces = detect_faces_with_template(gray, templates, template_info, template_threshold)\n",
    "            \n",
    "            for (x, y, w, h) in faces:\n",
    "                face_sizes.append((w + h) / 2)\n",
    "    \n",
    "    # Calculate average face size\n",
    "    avg_face_size = np.mean(face_sizes) if face_sizes else None\n",
    "    print(f\"Average face size: {avg_face_size:.2f}\" if avg_face_size else \"No faces detected in sampling\")\n",
    "    \n",
    "    # Reset video capture for second pass\n",
    "    cap.set(cv2.CAP_PROP_POS_FRAMES, 0)\n",
    "    \n",
    "    # Second pass: process frames with dynamic filtering\n",
    "    print(\"Second pass: processing frames...\")\n",
    "    frame_count = 0\n",
    "    recognition_stats = {'recognized': 0, 'unknown': 0, 'total_detections': 0}\n",
    "    \n",
    "    while True:\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "        \n",
    "        frame_count += 1\n",
    "        \n",
    "        # Detect and recognize faces using template matching and dual models\n",
    "        detection_results = detect_and_recognize_faces_dual_model(\n",
    "            frame, templates, template_info, dark_model_data, light_model_data, \n",
    "            similarity_threshold, template_threshold\n",
    "        )\n",
    "        \n",
    "        # Update statistics\n",
    "        for (_, _, _, _, _, _, is_recognized) in detection_results:\n",
    "            recognition_stats['total_detections'] += 1\n",
    "            if is_recognized:\n",
    "                recognition_stats['recognized'] += 1\n",
    "            else:\n",
    "                recognition_stats['unknown'] += 1\n",
    "        \n",
    "        # Draw annotations with dynamic filtering\n",
    "        annotated_frame = draw_face_annotations(frame, detection_results, avg_face_size)\n",
    "        \n",
    "        out.write(annotated_frame)\n",
    "        \n",
    "        if frame_count % 30 == 0:  # Print every 30 frames\n",
    "            progress = (frame_count / total_frames) * 100\n",
    "            print(f\"Progress: {progress:.1f}% ({frame_count}/{total_frames})\")\n",
    "    \n",
    "    cap.release()\n",
    "    out.release()\n",
    "    \n",
    "    print(f\"\\n=== Processing Complete ===\")\n",
    "    print(f\"Output video saved to: {output_video_path}\")\n",
    "    print(f\"Total frames processed: {frame_count}\")\n",
    "    print(f\"Total face detections: {recognition_stats['total_detections']}\")\n",
    "    print(f\"Recognized faces: {recognition_stats['recognized']}\")\n",
    "    print(f\"Unknown faces: {recognition_stats['unknown']}\")\n",
    "    \n",
    "    if recognition_stats['total_detections'] > 0:\n",
    "        recognition_rate = (recognition_stats['recognized'] / recognition_stats['total_detections']) * 100\n",
    "        print(f\"Recognition rate: {recognition_rate:.1f}%\")\n",
    "    \n",
    "    return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4008ead1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Process live camera feed to detect and recognize faces in real-time using template matching and dual models\n",
    "\n",
    "def process_live_camera(dark_model_path, light_model_path, similarity_threshold=0.7, template_threshold=0.7):\n",
    "\n",
    "    # Load dual PCA models\n",
    "    dark_model_data, light_model_data = load_dual_pca_models(dark_model_path, light_model_path)\n",
    "    if dark_model_data is None or light_model_data is None:\n",
    "        return False\n",
    "    \n",
    "    # Load face templates\n",
    "    templates, template_info = load_face_templates()\n",
    "    if len(templates) == 0:\n",
    "        print(\"Error: No face templates loaded\")\n",
    "        return False\n",
    "    \n",
    "    # Open camera\n",
    "    cap = cv2.VideoCapture(0)\n",
    "    if not cap.isOpened():\n",
    "        print(\"Error: Could not open camera\")\n",
    "        return False\n",
    "    \n",
    "    print(\"Live camera face recognition started. Press 'q' to quit.\")\n",
    "    print(f\"Using {len(templates)} face templates for detection\")\n",
    "    \n",
    "    # Initialize face size history for dynamic filtering\n",
    "    face_size_history = []\n",
    "    max_history_size = 50\n",
    "    \n",
    "    # Process frames in real-time\n",
    "    while True:\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            print(\"Error: Could not read frame from camera\")\n",
    "            break\n",
    "        \n",
    "        # Detect and recognize faces using template matching and dual models\n",
    "        detection_results = detect_and_recognize_faces_dual_model(\n",
    "            frame, templates, template_info, dark_model_data, light_model_data, \n",
    "            similarity_threshold, template_threshold\n",
    "        )\n",
    "        \n",
    "        # Update face size history for dynamic filtering\n",
    "        for (x, y, w, h, _, _, _) in detection_results:\n",
    "            face_size_history.append((w + h) / 2)\n",
    "        \n",
    "        # Maintain history size limit\n",
    "        if len(face_size_history) > max_history_size:\n",
    "            face_size_history = face_size_history[-max_history_size:]\n",
    "        \n",
    "        # Calculate dynamic average face size\n",
    "        avg_face_size = np.mean(face_size_history) if face_size_history else None\n",
    "        \n",
    "        # Draw annotations with dynamic filtering\n",
    "        annotated_frame = draw_face_annotations(frame, detection_results, avg_face_size)\n",
    "        \n",
    "        cv2.imshow('Live Face Recognition (Template Matching) - Press q to quit', annotated_frame)\n",
    "        \n",
    "        # Check for 'q' key press to quit\n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            break\n",
    "    \n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()\n",
    "    \n",
    "    print(\"Live camera face recognition stopped.\")\n",
    "    return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1ec44dc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuration - Dual model paths\n",
    "dark_model_file = \"models/Joseph_Lai_dark_pca_model.pkl\"\n",
    "light_model_file = \"models/Joseph_Lai_light_pca_model.pkl\"\n",
    "similarity_threshold = 0.8\n",
    "template_threshold = 0.7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "efdce7c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if both model files exist\n",
    "if not os.path.exists(dark_model_file):\n",
    "    raise FileNotFoundError(f\"Dark PCA model not found: {dark_model_file}\")\n",
    "if not os.path.exists(light_model_file):\n",
    "    raise FileNotFoundError(f\"Light PCA model not found: {light_model_file}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "8f0687d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting live camera mode with template matching...\n",
      "=== Loading Dual PCA Models ===\n",
      "PCA model loaded successfully from: models/Joseph_Lai_dark_pca_model.pkl\n",
      "Person: Joseph_Lai\n",
      "Training timestamp: 2025-08-20T04:03:56.181543\n",
      "Number of components: 50\n",
      "Face dimensions: 10000\n",
      "PCA model loaded successfully from: models/Joseph_Lai_light_pca_model.pkl\n",
      "Person: Joseph_Lai\n",
      "Training timestamp: 2025-08-20T04:03:56.502150\n",
      "Number of components: 50\n",
      "Face dimensions: 10000\n",
      "Both models loaded successfully!\n",
      "Loading face templates from: faces\n",
      "Found 512 template images in Dark_version\n",
      "Found 229 template images in Light_version\n",
      "Successfully loaded 20 face templates\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Live camera face recognition started. Press 'q' to quit.\n",
      "Using 20 face templates for detection\n",
      "Face 1 at position (482, 301, 76x76):\n",
      "  Dark model:  similarity=0.9016, threshold=0.8000\n",
      "  Light model: similarity=0.7064, threshold=0.8000\n",
      "  Best confidence: 0.9016, Status: RECOGNIZED\n",
      "Face 2 at position (121, 388, 62x62):\n",
      "  Dark model:  similarity=0.8050, threshold=0.8000\n",
      "  Light model: similarity=0.3788, threshold=0.8000\n",
      "  Best confidence: 0.8050, Status: RECOGNIZED\n",
      "Face 3 at position (226, 304, 76x76):\n",
      "  Dark model:  similarity=0.6320, threshold=0.8000\n",
      "  Light model: similarity=0.6327, threshold=0.8000\n",
      "  Best confidence: 0.6327, Status: UNKNOWN\n",
      "Face 1 at position (478, 296, 76x76):\n",
      "  Dark model:  similarity=0.9052, threshold=0.8000\n",
      "  Light model: similarity=0.6974, threshold=0.8000\n",
      "  Best confidence: 0.9052, Status: RECOGNIZED\n",
      "Face 2 at position (121, 388, 62x62):\n",
      "  Dark model:  similarity=0.8285, threshold=0.8000\n",
      "  Light model: similarity=0.3987, threshold=0.8000\n",
      "  Best confidence: 0.8285, Status: RECOGNIZED\n",
      "Face 3 at position (228, 310, 62x62):\n",
      "  Dark model:  similarity=0.4552, threshold=0.8000\n",
      "  Light model: similarity=0.7205, threshold=0.8000\n",
      "  Best confidence: 0.7205, Status: UNKNOWN\n",
      "Face 1 at position (469, 290, 76x76):\n",
      "  Dark model:  similarity=0.9012, threshold=0.8000\n",
      "  Light model: similarity=0.7048, threshold=0.8000\n",
      "  Best confidence: 0.9012, Status: RECOGNIZED\n",
      "Face 2 at position (222, 309, 62x62):\n",
      "  Dark model:  similarity=0.6249, threshold=0.8000\n",
      "  Light model: similarity=0.5488, threshold=0.8000\n",
      "  Best confidence: 0.6249, Status: UNKNOWN\n",
      "Face 3 at position (121, 387, 62x62):\n",
      "  Dark model:  similarity=0.8199, threshold=0.8000\n",
      "  Light model: similarity=0.3914, threshold=0.8000\n",
      "  Best confidence: 0.8199, Status: RECOGNIZED\n",
      "Face 1 at position (462, 284, 76x76):\n",
      "  Dark model:  similarity=0.9013, threshold=0.8000\n",
      "  Light model: similarity=0.7019, threshold=0.8000\n",
      "  Best confidence: 0.9013, Status: RECOGNIZED\n",
      "Face 2 at position (121, 386, 62x62):\n",
      "  Dark model:  similarity=0.8143, threshold=0.8000\n",
      "  Light model: similarity=0.3763, threshold=0.8000\n",
      "  Best confidence: 0.8143, Status: RECOGNIZED\n",
      "Face 3 at position (218, 308, 62x62):\n",
      "  Dark model:  similarity=0.6039, threshold=0.8000\n",
      "  Light model: similarity=0.5223, threshold=0.8000\n",
      "  Best confidence: 0.6039, Status: UNKNOWN\n",
      "Face 1 at position (121, 388, 62x62):\n",
      "  Dark model:  similarity=0.8326, threshold=0.8000\n",
      "  Light model: similarity=0.4095, threshold=0.8000\n",
      "  Best confidence: 0.8326, Status: RECOGNIZED\n",
      "Face 2 at position (474, 297, 62x62):\n",
      "  Dark model:  similarity=0.8972, threshold=0.8000\n",
      "  Light model: similarity=0.7057, threshold=0.8000\n",
      "  Best confidence: 0.8972, Status: RECOGNIZED\n",
      "Face 3 at position (213, 301, 76x76):\n",
      "  Dark model:  similarity=0.6520, threshold=0.8000\n",
      "  Light model: similarity=0.6580, threshold=0.8000\n",
      "  Best confidence: 0.6580, Status: UNKNOWN\n",
      "Face 1 at position (474, 294, 62x62):\n",
      "  Dark model:  similarity=0.9012, threshold=0.8000\n",
      "  Light model: similarity=0.7025, threshold=0.8000\n",
      "  Best confidence: 0.9012, Status: RECOGNIZED\n",
      "Face 2 at position (121, 388, 62x62):\n",
      "  Dark model:  similarity=0.8255, threshold=0.8000\n",
      "  Light model: similarity=0.3999, threshold=0.8000\n",
      "  Best confidence: 0.8255, Status: RECOGNIZED\n",
      "Face 3 at position (215, 301, 76x76):\n",
      "  Dark model:  similarity=0.6151, threshold=0.8000\n",
      "  Light model: similarity=0.6536, threshold=0.8000\n",
      "  Best confidence: 0.6536, Status: UNKNOWN\n",
      "Face 1 at position (471, 296, 76x76):\n",
      "  Dark model:  similarity=0.8974, threshold=0.8000\n",
      "  Light model: similarity=0.6941, threshold=0.8000\n",
      "  Best confidence: 0.8974, Status: RECOGNIZED\n",
      "Face 2 at position (121, 388, 62x62):\n",
      "  Dark model:  similarity=0.8206, threshold=0.8000\n",
      "  Light model: similarity=0.3874, threshold=0.8000\n",
      "  Best confidence: 0.8206, Status: RECOGNIZED\n",
      "Face 3 at position (216, 303, 76x76):\n",
      "  Dark model:  similarity=0.5908, threshold=0.8000\n",
      "  Light model: similarity=0.6667, threshold=0.8000\n",
      "  Best confidence: 0.6667, Status: UNKNOWN\n",
      "Face 1 at position (470, 294, 76x76):\n",
      "  Dark model:  similarity=0.8990, threshold=0.8000\n",
      "  Light model: similarity=0.6921, threshold=0.8000\n",
      "  Best confidence: 0.8990, Status: RECOGNIZED\n",
      "Face 2 at position (121, 388, 62x62):\n",
      "  Dark model:  similarity=0.8267, threshold=0.8000\n",
      "  Light model: similarity=0.3873, threshold=0.8000\n",
      "  Best confidence: 0.8267, Status: RECOGNIZED\n",
      "Face 3 at position (216, 301, 76x76):\n",
      "  Dark model:  similarity=0.6888, threshold=0.8000\n",
      "  Light model: similarity=0.6349, threshold=0.8000\n",
      "  Best confidence: 0.6888, Status: UNKNOWN\n",
      "Face 1 at position (469, 292, 76x76):\n",
      "  Dark model:  similarity=0.9022, threshold=0.8000\n",
      "  Light model: similarity=0.6952, threshold=0.8000\n",
      "  Best confidence: 0.9022, Status: RECOGNIZED\n",
      "Face 2 at position (121, 388, 62x62):\n",
      "  Dark model:  similarity=0.8275, threshold=0.8000\n",
      "  Light model: similarity=0.4170, threshold=0.8000\n",
      "  Best confidence: 0.8275, Status: RECOGNIZED\n",
      "Face 3 at position (216, 301, 76x76):\n",
      "  Dark model:  similarity=0.7008, threshold=0.8000\n",
      "  Light model: similarity=0.6134, threshold=0.8000\n",
      "  Best confidence: 0.7008, Status: UNKNOWN\n",
      "Face 1 at position (471, 295, 76x76):\n",
      "  Dark model:  similarity=0.9025, threshold=0.8000\n",
      "  Light model: similarity=0.6989, threshold=0.8000\n",
      "  Best confidence: 0.9025, Status: RECOGNIZED\n",
      "Face 2 at position (121, 388, 62x62):\n",
      "  Dark model:  similarity=0.8266, threshold=0.8000\n",
      "  Light model: similarity=0.4162, threshold=0.8000\n",
      "  Best confidence: 0.8266, Status: RECOGNIZED\n",
      "Face 3 at position (220, 311, 62x62):\n",
      "  Dark model:  similarity=0.4812, threshold=0.8000\n",
      "  Light model: similarity=0.7194, threshold=0.8000\n",
      "  Best confidence: 0.7194, Status: UNKNOWN\n",
      "Face 1 at position (471, 294, 76x76):\n",
      "  Dark model:  similarity=0.9049, threshold=0.8000\n",
      "  Light model: similarity=0.6997, threshold=0.8000\n",
      "  Best confidence: 0.9049, Status: RECOGNIZED\n",
      "Face 2 at position (121, 388, 62x62):\n",
      "  Dark model:  similarity=0.8309, threshold=0.8000\n",
      "  Light model: similarity=0.4196, threshold=0.8000\n",
      "  Best confidence: 0.8309, Status: RECOGNIZED\n",
      "Face 3 at position (217, 303, 76x76):\n",
      "  Dark model:  similarity=0.7474, threshold=0.8000\n",
      "  Light model: similarity=0.6024, threshold=0.8000\n",
      "  Best confidence: 0.7474, Status: UNKNOWN\n",
      "Face 1 at position (467, 293, 76x76):\n",
      "  Dark model:  similarity=0.9032, threshold=0.8000\n",
      "  Light model: similarity=0.6994, threshold=0.8000\n",
      "  Best confidence: 0.9032, Status: RECOGNIZED\n",
      "Face 2 at position (121, 388, 62x62):\n",
      "  Dark model:  similarity=0.8231, threshold=0.8000\n",
      "  Light model: similarity=0.4225, threshold=0.8000\n",
      "  Best confidence: 0.8231, Status: RECOGNIZED\n",
      "Face 3 at position (217, 309, 62x62):\n",
      "  Dark model:  similarity=0.4780, threshold=0.8000\n",
      "  Light model: similarity=0.7040, threshold=0.8000\n",
      "  Best confidence: 0.7040, Status: UNKNOWN\n",
      "Face 1 at position (220, 303, 62x62):\n",
      "  Dark model:  similarity=0.3772, threshold=0.8000\n",
      "  Light model: similarity=0.6824, threshold=0.8000\n",
      "  Best confidence: 0.6824, Status: UNKNOWN\n",
      "Face 2 at position (469, 291, 76x76):\n",
      "  Dark model:  similarity=0.8983, threshold=0.8000\n",
      "  Light model: similarity=0.6905, threshold=0.8000\n",
      "  Best confidence: 0.8983, Status: RECOGNIZED\n",
      "Face 3 at position (121, 388, 62x62):\n",
      "  Dark model:  similarity=0.8316, threshold=0.8000\n",
      "  Light model: similarity=0.4296, threshold=0.8000\n",
      "  Best confidence: 0.8316, Status: RECOGNIZED\n",
      "Face 1 at position (218, 304, 62x62):\n",
      "  Dark model:  similarity=0.3890, threshold=0.8000\n",
      "  Light model: similarity=0.6833, threshold=0.8000\n",
      "  Best confidence: 0.6833, Status: UNKNOWN\n",
      "Face 2 at position (471, 293, 62x62):\n",
      "  Dark model:  similarity=0.9035, threshold=0.8000\n",
      "  Light model: similarity=0.7044, threshold=0.8000\n",
      "  Best confidence: 0.9035, Status: RECOGNIZED\n",
      "Face 3 at position (121, 388, 62x62):\n",
      "  Dark model:  similarity=0.8253, threshold=0.8000\n",
      "  Light model: similarity=0.4033, threshold=0.8000\n",
      "  Best confidence: 0.8253, Status: RECOGNIZED\n",
      "Face 1 at position (467, 292, 76x76):\n",
      "  Dark model:  similarity=0.9040, threshold=0.8000\n",
      "  Light model: similarity=0.6984, threshold=0.8000\n",
      "  Best confidence: 0.9040, Status: RECOGNIZED\n",
      "Face 2 at position (121, 387, 62x62):\n",
      "  Dark model:  similarity=0.8241, threshold=0.8000\n",
      "  Light model: similarity=0.3756, threshold=0.8000\n",
      "  Best confidence: 0.8241, Status: RECOGNIZED\n",
      "Face 3 at position (216, 300, 76x76):\n",
      "  Dark model:  similarity=0.7053, threshold=0.8000\n",
      "  Light model: similarity=0.6137, threshold=0.8000\n",
      "  Best confidence: 0.7053, Status: UNKNOWN\n",
      "Face 1 at position (466, 290, 76x76):\n",
      "  Dark model:  similarity=0.9046, threshold=0.8000\n",
      "  Light model: similarity=0.6985, threshold=0.8000\n",
      "  Best confidence: 0.9046, Status: RECOGNIZED\n",
      "Face 2 at position (121, 388, 62x62):\n",
      "  Dark model:  similarity=0.8274, threshold=0.8000\n",
      "  Light model: similarity=0.4241, threshold=0.8000\n",
      "  Best confidence: 0.8274, Status: RECOGNIZED\n",
      "Face 3 at position (218, 308, 62x62):\n",
      "  Dark model:  similarity=0.5003, threshold=0.8000\n",
      "  Light model: similarity=0.7353, threshold=0.8000\n",
      "  Best confidence: 0.7353, Status: UNKNOWN\n",
      "Face 1 at position (463, 290, 76x76):\n",
      "  Dark model:  similarity=0.9056, threshold=0.8000\n",
      "  Light model: similarity=0.6956, threshold=0.8000\n",
      "  Best confidence: 0.9056, Status: RECOGNIZED\n",
      "Face 2 at position (121, 388, 62x62):\n",
      "  Dark model:  similarity=0.8288, threshold=0.8000\n",
      "  Light model: similarity=0.4184, threshold=0.8000\n",
      "  Best confidence: 0.8288, Status: RECOGNIZED\n",
      "Face 1 at position (457, 285, 76x76):\n",
      "  Dark model:  similarity=0.9102, threshold=0.8000\n",
      "  Light model: similarity=0.7018, threshold=0.8000\n",
      "  Best confidence: 0.9102, Status: RECOGNIZED\n",
      "Face 2 at position (120, 388, 62x62):\n",
      "  Dark model:  similarity=0.8061, threshold=0.8000\n",
      "  Light model: similarity=0.2562, threshold=0.8000\n",
      "  Best confidence: 0.8061, Status: RECOGNIZED\n",
      "Face 3 at position (210, 312, 62x62):\n",
      "  Dark model:  similarity=0.5045, threshold=0.8000\n",
      "  Light model: similarity=0.6987, threshold=0.8000\n",
      "  Best confidence: 0.6987, Status: UNKNOWN\n",
      "Live camera face recognition stopped.\n"
     ]
    }
   ],
   "source": [
    "# if u using camera run this\n",
    "# Live camera mode\n",
    "print(\"Starting live camera mode with template matching...\")\n",
    "success = process_live_camera(dark_model_file, light_model_file, similarity_threshold, template_threshold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0187e92f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing video file with template matching: C:\\Users\\Asus\\Desktop\\face_detection\\videos\\test.mp4\n",
      "=== Loading Dual PCA Models ===\n",
      "PCA model loaded successfully from: models/Joseph_Lai_dark_pca_model.pkl\n",
      "Person: Joseph_Lai\n",
      "Training timestamp: 2025-08-20T04:03:56.181543\n",
      "Number of components: 50\n",
      "Face dimensions: 10000\n",
      "PCA model loaded successfully from: models/Joseph_Lai_light_pca_model.pkl\n",
      "Person: Joseph_Lai\n",
      "Training timestamp: 2025-08-20T04:03:56.502150\n",
      "Number of components: 50\n",
      "Face dimensions: 10000\n",
      "Both models loaded successfully!\n",
      "Loading face templates from: faces\n",
      "Found 512 template images in Dark_version\n",
      "Found 229 template images in Light_version\n",
      "Successfully loaded 20 face templates\n",
      "Processing video: C:\\Users\\Asus\\Desktop\\face_detection\\videos\\test.mp4\n",
      "Video properties: 960x544, 30 FPS, 184 frames\n",
      "Using 20 face templates for detection\n",
      "First pass: collecting face sizes...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average face size: 64.96\n",
      "Second pass: processing frames...\n",
      "Face 1 at position (121, 369, 62x62):\n",
      "  Dark model:  similarity=0.9117, threshold=0.8000\n",
      "  Light model: similarity=0.6676, threshold=0.8000\n",
      "  Best confidence: 0.9117, Status: RECOGNIZED\n",
      "Face 1 at position (121, 369, 62x62):\n",
      "  Dark model:  similarity=0.9119, threshold=0.8000\n",
      "  Light model: similarity=0.6678, threshold=0.8000\n",
      "  Best confidence: 0.9119, Status: RECOGNIZED\n",
      "Face 1 at position (121, 368, 62x62):\n",
      "  Dark model:  similarity=0.9124, threshold=0.8000\n",
      "  Light model: similarity=0.6678, threshold=0.8000\n",
      "  Best confidence: 0.9124, Status: RECOGNIZED\n",
      "Face 1 at position (121, 368, 62x62):\n",
      "  Dark model:  similarity=0.9122, threshold=0.8000\n",
      "  Light model: similarity=0.6679, threshold=0.8000\n",
      "  Best confidence: 0.9122, Status: RECOGNIZED\n",
      "Face 1 at position (121, 370, 62x62):\n",
      "  Dark model:  similarity=0.9131, threshold=0.8000\n",
      "  Light model: similarity=0.6678, threshold=0.8000\n",
      "  Best confidence: 0.9131, Status: RECOGNIZED\n",
      "Face 1 at position (121, 370, 62x62):\n",
      "  Dark model:  similarity=0.9119, threshold=0.8000\n",
      "  Light model: similarity=0.6674, threshold=0.8000\n",
      "  Best confidence: 0.9119, Status: RECOGNIZED\n",
      "Face 1 at position (121, 370, 62x62):\n",
      "  Dark model:  similarity=0.9121, threshold=0.8000\n",
      "  Light model: similarity=0.6675, threshold=0.8000\n",
      "  Best confidence: 0.9121, Status: RECOGNIZED\n",
      "Face 1 at position (121, 370, 62x62):\n",
      "  Dark model:  similarity=0.9124, threshold=0.8000\n",
      "  Light model: similarity=0.6675, threshold=0.8000\n",
      "  Best confidence: 0.9124, Status: RECOGNIZED\n",
      "Face 1 at position (121, 369, 62x62):\n",
      "  Dark model:  similarity=0.9112, threshold=0.8000\n",
      "  Light model: similarity=0.6662, threshold=0.8000\n",
      "  Best confidence: 0.9112, Status: RECOGNIZED\n",
      "Face 1 at position (121, 369, 62x62):\n",
      "  Dark model:  similarity=0.9123, threshold=0.8000\n",
      "  Light model: similarity=0.6673, threshold=0.8000\n",
      "  Best confidence: 0.9123, Status: RECOGNIZED\n",
      "Face 1 at position (121, 369, 62x62):\n",
      "  Dark model:  similarity=0.9130, threshold=0.8000\n",
      "  Light model: similarity=0.6673, threshold=0.8000\n",
      "  Best confidence: 0.9130, Status: RECOGNIZED\n",
      "Face 1 at position (121, 368, 62x62):\n",
      "  Dark model:  similarity=0.9125, threshold=0.8000\n",
      "  Light model: similarity=0.6669, threshold=0.8000\n",
      "  Best confidence: 0.9125, Status: RECOGNIZED\n",
      "Face 1 at position (121, 369, 62x62):\n",
      "  Dark model:  similarity=0.9132, threshold=0.8000\n",
      "  Light model: similarity=0.6675, threshold=0.8000\n",
      "  Best confidence: 0.9132, Status: RECOGNIZED\n",
      "Face 1 at position (121, 370, 62x62):\n",
      "  Dark model:  similarity=0.9131, threshold=0.8000\n",
      "  Light model: similarity=0.6675, threshold=0.8000\n",
      "  Best confidence: 0.9131, Status: RECOGNIZED\n",
      "Face 1 at position (121, 370, 62x62):\n",
      "  Dark model:  similarity=0.9138, threshold=0.8000\n",
      "  Light model: similarity=0.6680, threshold=0.8000\n",
      "  Best confidence: 0.9138, Status: RECOGNIZED\n",
      "Face 1 at position (121, 370, 62x62):\n",
      "  Dark model:  similarity=0.9140, threshold=0.8000\n",
      "  Light model: similarity=0.6682, threshold=0.8000\n",
      "  Best confidence: 0.9140, Status: RECOGNIZED\n",
      "Face 1 at position (121, 369, 62x62):\n",
      "  Dark model:  similarity=0.9142, threshold=0.8000\n",
      "  Light model: similarity=0.6688, threshold=0.8000\n",
      "  Best confidence: 0.9142, Status: RECOGNIZED\n",
      "Face 1 at position (121, 369, 62x62):\n",
      "  Dark model:  similarity=0.9142, threshold=0.8000\n",
      "  Light model: similarity=0.6687, threshold=0.8000\n",
      "  Best confidence: 0.9142, Status: RECOGNIZED\n",
      "Face 1 at position (121, 369, 62x62):\n",
      "  Dark model:  similarity=0.9148, threshold=0.8000\n",
      "  Light model: similarity=0.6703, threshold=0.8000\n",
      "  Best confidence: 0.9148, Status: RECOGNIZED\n",
      "Face 1 at position (121, 368, 62x62):\n",
      "  Dark model:  similarity=0.9142, threshold=0.8000\n",
      "  Light model: similarity=0.6703, threshold=0.8000\n",
      "  Best confidence: 0.9142, Status: RECOGNIZED\n",
      "Face 1 at position (121, 369, 62x62):\n",
      "  Dark model:  similarity=0.9145, threshold=0.8000\n",
      "  Light model: similarity=0.6703, threshold=0.8000\n",
      "  Best confidence: 0.9145, Status: RECOGNIZED\n",
      "Face 1 at position (121, 369, 62x62):\n",
      "  Dark model:  similarity=0.9138, threshold=0.8000\n",
      "  Light model: similarity=0.6697, threshold=0.8000\n",
      "  Best confidence: 0.9138, Status: RECOGNIZED\n",
      "Face 1 at position (121, 370, 62x62):\n",
      "  Dark model:  similarity=0.9142, threshold=0.8000\n",
      "  Light model: similarity=0.6697, threshold=0.8000\n",
      "  Best confidence: 0.9142, Status: RECOGNIZED\n",
      "Face 1 at position (121, 370, 62x62):\n",
      "  Dark model:  similarity=0.9143, threshold=0.8000\n",
      "  Light model: similarity=0.6702, threshold=0.8000\n",
      "  Best confidence: 0.9143, Status: RECOGNIZED\n",
      "Face 1 at position (121, 370, 62x62):\n",
      "  Dark model:  similarity=0.9147, threshold=0.8000\n",
      "  Light model: similarity=0.6712, threshold=0.8000\n",
      "  Best confidence: 0.9147, Status: RECOGNIZED\n",
      "Face 1 at position (121, 369, 62x62):\n",
      "  Dark model:  similarity=0.9154, threshold=0.8000\n",
      "  Light model: similarity=0.6714, threshold=0.8000\n",
      "  Best confidence: 0.9154, Status: RECOGNIZED\n",
      "Face 1 at position (120, 369, 62x62):\n",
      "  Dark model:  similarity=0.9035, threshold=0.8000\n",
      "  Light model: similarity=0.6650, threshold=0.8000\n",
      "  Best confidence: 0.9035, Status: RECOGNIZED\n",
      "Face 1 at position (120, 369, 62x62):\n",
      "  Dark model:  similarity=0.9041, threshold=0.8000\n",
      "  Light model: similarity=0.6646, threshold=0.8000\n",
      "  Best confidence: 0.9041, Status: RECOGNIZED\n",
      "Face 1 at position (120, 369, 62x62):\n",
      "  Dark model:  similarity=0.9029, threshold=0.8000\n",
      "  Light model: similarity=0.6645, threshold=0.8000\n",
      "  Best confidence: 0.9029, Status: RECOGNIZED\n",
      "Face 1 at position (120, 370, 62x62):\n",
      "  Dark model:  similarity=0.9028, threshold=0.8000\n",
      "  Light model: similarity=0.6663, threshold=0.8000\n",
      "  Best confidence: 0.9028, Status: RECOGNIZED\n",
      "Progress: 16.3% (30/184)\n",
      "Face 1 at position (120, 370, 62x62):\n",
      "  Dark model:  similarity=0.9039, threshold=0.8000\n",
      "  Light model: similarity=0.6648, threshold=0.8000\n",
      "  Best confidence: 0.9039, Status: RECOGNIZED\n",
      "Face 1 at position (120, 369, 62x62):\n",
      "  Dark model:  similarity=0.9037, threshold=0.8000\n",
      "  Light model: similarity=0.6640, threshold=0.8000\n",
      "  Best confidence: 0.9037, Status: RECOGNIZED\n",
      "Face 1 at position (120, 369, 62x62):\n",
      "  Dark model:  similarity=0.9036, threshold=0.8000\n",
      "  Light model: similarity=0.6650, threshold=0.8000\n",
      "  Best confidence: 0.9036, Status: RECOGNIZED\n",
      "Face 1 at position (120, 370, 62x62):\n",
      "  Dark model:  similarity=0.9034, threshold=0.8000\n",
      "  Light model: similarity=0.6657, threshold=0.8000\n",
      "  Best confidence: 0.9034, Status: RECOGNIZED\n",
      "Face 1 at position (120, 370, 62x62):\n",
      "  Dark model:  similarity=0.9040, threshold=0.8000\n",
      "  Light model: similarity=0.6656, threshold=0.8000\n",
      "  Best confidence: 0.9040, Status: RECOGNIZED\n",
      "Face 1 at position (120, 370, 62x62):\n",
      "  Dark model:  similarity=0.9045, threshold=0.8000\n",
      "  Light model: similarity=0.6650, threshold=0.8000\n",
      "  Best confidence: 0.9045, Status: RECOGNIZED\n",
      "Face 1 at position (120, 370, 62x62):\n",
      "  Dark model:  similarity=0.9046, threshold=0.8000\n",
      "  Light model: similarity=0.6659, threshold=0.8000\n",
      "  Best confidence: 0.9046, Status: RECOGNIZED\n",
      "Face 1 at position (120, 370, 62x62):\n",
      "  Dark model:  similarity=0.9042, threshold=0.8000\n",
      "  Light model: similarity=0.6660, threshold=0.8000\n",
      "  Best confidence: 0.9042, Status: RECOGNIZED\n",
      "Face 1 at position (120, 369, 62x62):\n",
      "  Dark model:  similarity=0.9036, threshold=0.8000\n",
      "  Light model: similarity=0.6650, threshold=0.8000\n",
      "  Best confidence: 0.9036, Status: RECOGNIZED\n",
      "Face 2 at position (326, 195, 62x62):\n",
      "  Dark model:  similarity=0.8943, threshold=0.8000\n",
      "  Light model: similarity=0.6943, threshold=0.8000\n",
      "  Best confidence: 0.8943, Status: RECOGNIZED\n",
      "Face 3 at position (428, 204, 142x142):\n",
      "  Dark model:  similarity=0.9250, threshold=0.8000\n",
      "  Light model: similarity=0.7311, threshold=0.8000\n",
      "  Best confidence: 0.9250, Status: RECOGNIZED\n",
      "Face 1 at position (120, 369, 62x62):\n",
      "  Dark model:  similarity=0.9039, threshold=0.8000\n",
      "  Light model: similarity=0.6648, threshold=0.8000\n",
      "  Best confidence: 0.9039, Status: RECOGNIZED\n",
      "Face 2 at position (321, 195, 62x62):\n",
      "  Dark model:  similarity=0.8994, threshold=0.8000\n",
      "  Light model: similarity=0.6941, threshold=0.8000\n",
      "  Best confidence: 0.8994, Status: RECOGNIZED\n",
      "Face 3 at position (424, 204, 142x142):\n",
      "  Dark model:  similarity=0.9205, threshold=0.8000\n",
      "  Light model: similarity=0.7321, threshold=0.8000\n",
      "  Best confidence: 0.9205, Status: RECOGNIZED\n",
      "Face 1 at position (120, 369, 62x62):\n",
      "  Dark model:  similarity=0.9042, threshold=0.8000\n",
      "  Light model: similarity=0.6657, threshold=0.8000\n",
      "  Best confidence: 0.9042, Status: RECOGNIZED\n",
      "Face 2 at position (316, 195, 62x62):\n",
      "  Dark model:  similarity=0.9013, threshold=0.8000\n",
      "  Light model: similarity=0.6928, threshold=0.8000\n",
      "  Best confidence: 0.9013, Status: RECOGNIZED\n",
      "Face 1 at position (120, 370, 62x62):\n",
      "  Dark model:  similarity=0.9047, threshold=0.8000\n",
      "  Light model: similarity=0.6653, threshold=0.8000\n",
      "  Best confidence: 0.9047, Status: RECOGNIZED\n",
      "Face 2 at position (311, 195, 62x62):\n",
      "  Dark model:  similarity=0.9023, threshold=0.8000\n",
      "  Light model: similarity=0.6910, threshold=0.8000\n",
      "  Best confidence: 0.9023, Status: RECOGNIZED\n",
      "Face 1 at position (120, 370, 62x62):\n",
      "  Dark model:  similarity=0.9095, threshold=0.8000\n",
      "  Light model: similarity=0.6649, threshold=0.8000\n",
      "  Best confidence: 0.9095, Status: RECOGNIZED\n",
      "Face 2 at position (306, 198, 62x62):\n",
      "  Dark model:  similarity=0.9059, threshold=0.8000\n",
      "  Light model: similarity=0.6882, threshold=0.8000\n",
      "  Best confidence: 0.9059, Status: RECOGNIZED\n",
      "Face 1 at position (120, 370, 62x62):\n",
      "  Dark model:  similarity=0.9112, threshold=0.8000\n",
      "  Light model: similarity=0.6658, threshold=0.8000\n",
      "  Best confidence: 0.9112, Status: RECOGNIZED\n",
      "Face 2 at position (301, 198, 62x62):\n",
      "  Dark model:  similarity=0.9085, threshold=0.8000\n",
      "  Light model: similarity=0.6843, threshold=0.8000\n",
      "  Best confidence: 0.9085, Status: RECOGNIZED\n",
      "Face 1 at position (120, 370, 62x62):\n",
      "  Dark model:  similarity=0.9119, threshold=0.8000\n",
      "  Light model: similarity=0.6672, threshold=0.8000\n",
      "  Best confidence: 0.9119, Status: RECOGNIZED\n",
      "Face 2 at position (297, 199, 62x62):\n",
      "  Dark model:  similarity=0.9084, threshold=0.8000\n",
      "  Light model: similarity=0.6850, threshold=0.8000\n",
      "  Best confidence: 0.9084, Status: RECOGNIZED\n",
      "Face 1 at position (120, 369, 62x62):\n",
      "  Dark model:  similarity=0.9132, threshold=0.8000\n",
      "  Light model: similarity=0.6684, threshold=0.8000\n",
      "  Best confidence: 0.9132, Status: RECOGNIZED\n",
      "Face 2 at position (293, 198, 62x62):\n",
      "  Dark model:  similarity=0.9041, threshold=0.8000\n",
      "  Light model: similarity=0.6889, threshold=0.8000\n",
      "  Best confidence: 0.9041, Status: RECOGNIZED\n",
      "Face 1 at position (120, 369, 62x62):\n",
      "  Dark model:  similarity=0.9131, threshold=0.8000\n",
      "  Light model: similarity=0.6686, threshold=0.8000\n",
      "  Best confidence: 0.9131, Status: RECOGNIZED\n",
      "Face 2 at position (288, 198, 62x62):\n",
      "  Dark model:  similarity=0.9025, threshold=0.8000\n",
      "  Light model: similarity=0.6894, threshold=0.8000\n",
      "  Best confidence: 0.9025, Status: RECOGNIZED\n",
      "Face 1 at position (120, 370, 62x62):\n",
      "  Dark model:  similarity=0.9135, threshold=0.8000\n",
      "  Light model: similarity=0.6687, threshold=0.8000\n",
      "  Best confidence: 0.9135, Status: RECOGNIZED\n",
      "Face 2 at position (283, 200, 62x62):\n",
      "  Dark model:  similarity=0.9030, threshold=0.8000\n",
      "  Light model: similarity=0.6900, threshold=0.8000\n",
      "  Best confidence: 0.9030, Status: RECOGNIZED\n",
      "Face 1 at position (120, 370, 62x62):\n",
      "  Dark model:  similarity=0.9120, threshold=0.8000\n",
      "  Light model: similarity=0.6669, threshold=0.8000\n",
      "  Best confidence: 0.9120, Status: RECOGNIZED\n",
      "Face 2 at position (277, 201, 62x62):\n",
      "  Dark model:  similarity=0.9037, threshold=0.8000\n",
      "  Light model: similarity=0.6887, threshold=0.8000\n",
      "  Best confidence: 0.9037, Status: RECOGNIZED\n",
      "Face 1 at position (120, 370, 62x62):\n",
      "  Dark model:  similarity=0.9089, threshold=0.8000\n",
      "  Light model: similarity=0.6650, threshold=0.8000\n",
      "  Best confidence: 0.9089, Status: RECOGNIZED\n",
      "Face 2 at position (271, 203, 62x62):\n",
      "  Dark model:  similarity=0.9050, threshold=0.8000\n",
      "  Light model: similarity=0.6878, threshold=0.8000\n",
      "  Best confidence: 0.9050, Status: RECOGNIZED\n",
      "Face 1 at position (120, 370, 62x62):\n",
      "  Dark model:  similarity=0.9083, threshold=0.8000\n",
      "  Light model: similarity=0.6648, threshold=0.8000\n",
      "  Best confidence: 0.9083, Status: RECOGNIZED\n",
      "Face 2 at position (265, 204, 62x62):\n",
      "  Dark model:  similarity=0.9040, threshold=0.8000\n",
      "  Light model: similarity=0.6885, threshold=0.8000\n",
      "  Best confidence: 0.9040, Status: RECOGNIZED\n",
      "Face 1 at position (120, 370, 62x62):\n",
      "  Dark model:  similarity=0.9065, threshold=0.8000\n",
      "  Light model: similarity=0.6657, threshold=0.8000\n",
      "  Best confidence: 0.9065, Status: RECOGNIZED\n",
      "Face 2 at position (258, 205, 62x62):\n",
      "  Dark model:  similarity=0.9052, threshold=0.8000\n",
      "  Light model: similarity=0.6865, threshold=0.8000\n",
      "  Best confidence: 0.9052, Status: RECOGNIZED\n",
      "Face 1 at position (120, 369, 62x62):\n",
      "  Dark model:  similarity=0.9050, threshold=0.8000\n",
      "  Light model: similarity=0.6638, threshold=0.8000\n",
      "  Best confidence: 0.9050, Status: RECOGNIZED\n",
      "Face 2 at position (252, 206, 62x62):\n",
      "  Dark model:  similarity=0.9049, threshold=0.8000\n",
      "  Light model: similarity=0.6890, threshold=0.8000\n",
      "  Best confidence: 0.9049, Status: RECOGNIZED\n",
      "Face 1 at position (120, 369, 62x62):\n",
      "  Dark model:  similarity=0.9050, threshold=0.8000\n",
      "  Light model: similarity=0.6641, threshold=0.8000\n",
      "  Best confidence: 0.9050, Status: RECOGNIZED\n",
      "Face 2 at position (246, 207, 62x62):\n",
      "  Dark model:  similarity=0.9040, threshold=0.8000\n",
      "  Light model: similarity=0.6910, threshold=0.8000\n",
      "  Best confidence: 0.9040, Status: RECOGNIZED\n",
      "Face 1 at position (120, 370, 62x62):\n",
      "  Dark model:  similarity=0.9057, threshold=0.8000\n",
      "  Light model: similarity=0.6644, threshold=0.8000\n",
      "  Best confidence: 0.9057, Status: RECOGNIZED\n",
      "Face 2 at position (239, 209, 62x62):\n",
      "  Dark model:  similarity=0.9051, threshold=0.8000\n",
      "  Light model: similarity=0.6896, threshold=0.8000\n",
      "  Best confidence: 0.9051, Status: RECOGNIZED\n",
      "Face 1 at position (120, 370, 62x62):\n",
      "  Dark model:  similarity=0.9043, threshold=0.8000\n",
      "  Light model: similarity=0.6651, threshold=0.8000\n",
      "  Best confidence: 0.9043, Status: RECOGNIZED\n",
      "Face 2 at position (233, 211, 62x62):\n",
      "  Dark model:  similarity=0.9051, threshold=0.8000\n",
      "  Light model: similarity=0.6927, threshold=0.8000\n",
      "  Best confidence: 0.9051, Status: RECOGNIZED\n",
      "Face 1 at position (120, 370, 62x62):\n",
      "  Dark model:  similarity=0.9065, threshold=0.8000\n",
      "  Light model: similarity=0.6657, threshold=0.8000\n",
      "  Best confidence: 0.9065, Status: RECOGNIZED\n",
      "Face 2 at position (226, 211, 62x62):\n",
      "  Dark model:  similarity=0.9042, threshold=0.8000\n",
      "  Light model: similarity=0.6924, threshold=0.8000\n",
      "  Best confidence: 0.9042, Status: RECOGNIZED\n",
      "Face 1 at position (120, 370, 62x62):\n",
      "  Dark model:  similarity=0.9050, threshold=0.8000\n",
      "  Light model: similarity=0.6663, threshold=0.8000\n",
      "  Best confidence: 0.9050, Status: RECOGNIZED\n",
      "Face 2 at position (220, 213, 62x62):\n",
      "  Dark model:  similarity=0.9043, threshold=0.8000\n",
      "  Light model: similarity=0.6941, threshold=0.8000\n",
      "  Best confidence: 0.9043, Status: RECOGNIZED\n",
      "Face 1 at position (120, 369, 62x62):\n",
      "  Dark model:  similarity=0.9040, threshold=0.8000\n",
      "  Light model: similarity=0.6652, threshold=0.8000\n",
      "  Best confidence: 0.9040, Status: RECOGNIZED\n",
      "Face 2 at position (213, 214, 62x62):\n",
      "  Dark model:  similarity=0.9053, threshold=0.8000\n",
      "  Light model: similarity=0.6915, threshold=0.8000\n",
      "  Best confidence: 0.9053, Status: RECOGNIZED\n",
      "Face 1 at position (121, 369, 62x62):\n",
      "  Dark model:  similarity=0.9143, threshold=0.8000\n",
      "  Light model: similarity=0.6694, threshold=0.8000\n",
      "  Best confidence: 0.9143, Status: RECOGNIZED\n",
      "Face 2 at position (208, 216, 62x62):\n",
      "  Dark model:  similarity=0.9055, threshold=0.8000\n",
      "  Light model: similarity=0.6931, threshold=0.8000\n",
      "  Best confidence: 0.9055, Status: RECOGNIZED\n",
      "Progress: 32.6% (60/184)\n",
      "Face 1 at position (121, 370, 62x62):\n",
      "  Dark model:  similarity=0.9140, threshold=0.8000\n",
      "  Light model: similarity=0.6689, threshold=0.8000\n",
      "  Best confidence: 0.9140, Status: RECOGNIZED\n",
      "Face 2 at position (202, 216, 62x62):\n",
      "  Dark model:  similarity=0.9035, threshold=0.8000\n",
      "  Light model: similarity=0.6931, threshold=0.8000\n",
      "  Best confidence: 0.9035, Status: RECOGNIZED\n",
      "Face 1 at position (121, 370, 62x62):\n",
      "  Dark model:  similarity=0.9109, threshold=0.8000\n",
      "  Light model: similarity=0.6657, threshold=0.8000\n",
      "  Best confidence: 0.9109, Status: RECOGNIZED\n",
      "Face 2 at position (197, 218, 62x62):\n",
      "  Dark model:  similarity=0.9049, threshold=0.8000\n",
      "  Light model: similarity=0.6933, threshold=0.8000\n",
      "  Best confidence: 0.9049, Status: RECOGNIZED\n",
      "Face 1 at position (121, 370, 62x62):\n",
      "  Dark model:  similarity=0.9091, threshold=0.8000\n",
      "  Light model: similarity=0.6659, threshold=0.8000\n",
      "  Best confidence: 0.9091, Status: RECOGNIZED\n",
      "Face 2 at position (192, 220, 62x62):\n",
      "  Dark model:  similarity=0.9056, threshold=0.8000\n",
      "  Light model: similarity=0.6936, threshold=0.8000\n",
      "  Best confidence: 0.9056, Status: RECOGNIZED\n",
      "Face 1 at position (121, 370, 62x62):\n",
      "  Dark model:  similarity=0.9071, threshold=0.8000\n",
      "  Light model: similarity=0.6658, threshold=0.8000\n",
      "  Best confidence: 0.9071, Status: RECOGNIZED\n",
      "Face 2 at position (188, 221, 62x62):\n",
      "  Dark model:  similarity=0.9048, threshold=0.8000\n",
      "  Light model: similarity=0.6954, threshold=0.8000\n",
      "  Best confidence: 0.9048, Status: RECOGNIZED\n",
      "Face 1 at position (121, 370, 62x62):\n",
      "  Dark model:  similarity=0.9051, threshold=0.8000\n",
      "  Light model: similarity=0.6658, threshold=0.8000\n",
      "  Best confidence: 0.9051, Status: RECOGNIZED\n",
      "Face 2 at position (183, 221, 62x62):\n",
      "  Dark model:  similarity=0.9063, threshold=0.8000\n",
      "  Light model: similarity=0.6931, threshold=0.8000\n",
      "  Best confidence: 0.9063, Status: RECOGNIZED\n",
      "Face 1 at position (121, 370, 62x62):\n",
      "  Dark model:  similarity=0.9038, threshold=0.8000\n",
      "  Light model: similarity=0.6662, threshold=0.8000\n",
      "  Best confidence: 0.9038, Status: RECOGNIZED\n",
      "Face 2 at position (180, 223, 62x62):\n",
      "  Dark model:  similarity=0.9073, threshold=0.8000\n",
      "  Light model: similarity=0.6943, threshold=0.8000\n",
      "  Best confidence: 0.9073, Status: RECOGNIZED\n",
      "Face 1 at position (121, 370, 62x62):\n",
      "  Dark model:  similarity=0.9037, threshold=0.8000\n",
      "  Light model: similarity=0.6664, threshold=0.8000\n",
      "  Best confidence: 0.9037, Status: RECOGNIZED\n",
      "Face 2 at position (178, 223, 62x62):\n",
      "  Dark model:  similarity=0.9038, threshold=0.8000\n",
      "  Light model: similarity=0.6973, threshold=0.8000\n",
      "  Best confidence: 0.9038, Status: RECOGNIZED\n",
      "Face 1 at position (121, 370, 62x62):\n",
      "  Dark model:  similarity=0.9039, threshold=0.8000\n",
      "  Light model: similarity=0.6666, threshold=0.8000\n",
      "  Best confidence: 0.9039, Status: RECOGNIZED\n",
      "Face 2 at position (176, 225, 62x62):\n",
      "  Dark model:  similarity=0.9047, threshold=0.8000\n",
      "  Light model: similarity=0.6973, threshold=0.8000\n",
      "  Best confidence: 0.9047, Status: RECOGNIZED\n",
      "Face 1 at position (121, 370, 62x62):\n",
      "  Dark model:  similarity=0.9040, threshold=0.8000\n",
      "  Light model: similarity=0.6658, threshold=0.8000\n",
      "  Best confidence: 0.9040, Status: RECOGNIZED\n",
      "Face 2 at position (175, 225, 62x62):\n",
      "  Dark model:  similarity=0.9034, threshold=0.8000\n",
      "  Light model: similarity=0.6977, threshold=0.8000\n",
      "  Best confidence: 0.9034, Status: RECOGNIZED\n",
      "Face 1 at position (121, 370, 62x62):\n",
      "  Dark model:  similarity=0.9041, threshold=0.8000\n",
      "  Light model: similarity=0.6662, threshold=0.8000\n",
      "  Best confidence: 0.9041, Status: RECOGNIZED\n",
      "Face 2 at position (174, 225, 62x62):\n",
      "  Dark model:  similarity=0.9038, threshold=0.8000\n",
      "  Light model: similarity=0.6954, threshold=0.8000\n",
      "  Best confidence: 0.9038, Status: RECOGNIZED\n",
      "Face 1 at position (121, 370, 62x62):\n",
      "  Dark model:  similarity=0.9042, threshold=0.8000\n",
      "  Light model: similarity=0.6658, threshold=0.8000\n",
      "  Best confidence: 0.9042, Status: RECOGNIZED\n",
      "Face 2 at position (174, 224, 62x62):\n",
      "  Dark model:  similarity=0.9019, threshold=0.8000\n",
      "  Light model: similarity=0.6964, threshold=0.8000\n",
      "  Best confidence: 0.9019, Status: RECOGNIZED\n",
      "Face 1 at position (121, 370, 62x62):\n",
      "  Dark model:  similarity=0.9039, threshold=0.8000\n",
      "  Light model: similarity=0.6653, threshold=0.8000\n",
      "  Best confidence: 0.9039, Status: RECOGNIZED\n",
      "Face 2 at position (175, 223, 62x62):\n",
      "  Dark model:  similarity=0.9000, threshold=0.8000\n",
      "  Light model: similarity=0.6973, threshold=0.8000\n",
      "  Best confidence: 0.9000, Status: RECOGNIZED\n",
      "Face 1 at position (122, 369, 62x62):\n",
      "  Dark model:  similarity=0.9125, threshold=0.8000\n",
      "  Light model: similarity=0.6670, threshold=0.8000\n",
      "  Best confidence: 0.9125, Status: RECOGNIZED\n",
      "Face 2 at position (176, 223, 62x62):\n",
      "  Dark model:  similarity=0.9026, threshold=0.8000\n",
      "  Light model: similarity=0.6959, threshold=0.8000\n",
      "  Best confidence: 0.9026, Status: RECOGNIZED\n",
      "Face 3 at position (119, 401, 62x62):\n",
      "  Dark model:  similarity=0.8584, threshold=0.8000\n",
      "  Light model: similarity=0.6462, threshold=0.8000\n",
      "  Best confidence: 0.8584, Status: RECOGNIZED\n",
      "Face 1 at position (122, 370, 62x62):\n",
      "  Dark model:  similarity=0.9125, threshold=0.8000\n",
      "  Light model: similarity=0.6671, threshold=0.8000\n",
      "  Best confidence: 0.9125, Status: RECOGNIZED\n",
      "Face 2 at position (178, 222, 62x62):\n",
      "  Dark model:  similarity=0.9026, threshold=0.8000\n",
      "  Light model: similarity=0.6955, threshold=0.8000\n",
      "  Best confidence: 0.9026, Status: RECOGNIZED\n",
      "Face 1 at position (121, 370, 62x62):\n",
      "  Dark model:  similarity=0.9042, threshold=0.8000\n",
      "  Light model: similarity=0.6635, threshold=0.8000\n",
      "  Best confidence: 0.9042, Status: RECOGNIZED\n",
      "Face 2 at position (181, 221, 62x62):\n",
      "  Dark model:  similarity=0.9015, threshold=0.8000\n",
      "  Light model: similarity=0.6957, threshold=0.8000\n",
      "  Best confidence: 0.9015, Status: RECOGNIZED\n",
      "Face 1 at position (122, 370, 62x62):\n",
      "  Dark model:  similarity=0.9102, threshold=0.8000\n",
      "  Light model: similarity=0.6650, threshold=0.8000\n",
      "  Best confidence: 0.9102, Status: RECOGNIZED\n",
      "Face 2 at position (186, 220, 62x62):\n",
      "  Dark model:  similarity=0.9009, threshold=0.8000\n",
      "  Light model: similarity=0.6981, threshold=0.8000\n",
      "  Best confidence: 0.9009, Status: RECOGNIZED\n",
      "Face 1 at position (122, 369, 62x62):\n",
      "  Dark model:  similarity=0.9071, threshold=0.8000\n",
      "  Light model: similarity=0.6645, threshold=0.8000\n",
      "  Best confidence: 0.9071, Status: RECOGNIZED\n",
      "Face 2 at position (191, 216, 62x62):\n",
      "  Dark model:  similarity=0.9002, threshold=0.8000\n",
      "  Light model: similarity=0.6980, threshold=0.8000\n",
      "  Best confidence: 0.9002, Status: RECOGNIZED\n",
      "Face 1 at position (122, 368, 62x62):\n",
      "  Dark model:  similarity=0.9077, threshold=0.8000\n",
      "  Light model: similarity=0.6644, threshold=0.8000\n",
      "  Best confidence: 0.9077, Status: RECOGNIZED\n",
      "Face 2 at position (197, 213, 62x62):\n",
      "  Dark model:  similarity=0.9011, threshold=0.8000\n",
      "  Light model: similarity=0.6970, threshold=0.8000\n",
      "  Best confidence: 0.9011, Status: RECOGNIZED\n",
      "Face 1 at position (122, 368, 62x62):\n",
      "  Dark model:  similarity=0.9077, threshold=0.8000\n",
      "  Light model: similarity=0.6640, threshold=0.8000\n",
      "  Best confidence: 0.9077, Status: RECOGNIZED\n",
      "Face 2 at position (205, 210, 62x62):\n",
      "  Dark model:  similarity=0.8997, threshold=0.8000\n",
      "  Light model: similarity=0.6981, threshold=0.8000\n",
      "  Best confidence: 0.8997, Status: RECOGNIZED\n",
      "Face 1 at position (122, 370, 62x62):\n",
      "  Dark model:  similarity=0.9054, threshold=0.8000\n",
      "  Light model: similarity=0.6657, threshold=0.8000\n",
      "  Best confidence: 0.9054, Status: RECOGNIZED\n",
      "Face 2 at position (213, 207, 62x62):\n",
      "  Dark model:  similarity=0.8994, threshold=0.8000\n",
      "  Light model: similarity=0.6985, threshold=0.8000\n",
      "  Best confidence: 0.8994, Status: RECOGNIZED\n",
      "Face 1 at position (122, 371, 62x62):\n",
      "  Dark model:  similarity=0.9049, threshold=0.8000\n",
      "  Light model: similarity=0.6654, threshold=0.8000\n",
      "  Best confidence: 0.9049, Status: RECOGNIZED\n",
      "Face 2 at position (221, 206, 62x62):\n",
      "  Dark model:  similarity=0.9032, threshold=0.8000\n",
      "  Light model: similarity=0.6938, threshold=0.8000\n",
      "  Best confidence: 0.9032, Status: RECOGNIZED\n",
      "Face 1 at position (122, 371, 62x62):\n",
      "  Dark model:  similarity=0.9043, threshold=0.8000\n",
      "  Light model: similarity=0.6647, threshold=0.8000\n",
      "  Best confidence: 0.9043, Status: RECOGNIZED\n",
      "Face 2 at position (231, 203, 62x62):\n",
      "  Dark model:  similarity=0.9005, threshold=0.8000\n",
      "  Light model: similarity=0.6970, threshold=0.8000\n",
      "  Best confidence: 0.9005, Status: RECOGNIZED\n",
      "Face 1 at position (122, 371, 62x62):\n",
      "  Dark model:  similarity=0.9085, threshold=0.8000\n",
      "  Light model: similarity=0.6649, threshold=0.8000\n",
      "  Best confidence: 0.9085, Status: RECOGNIZED\n",
      "Face 2 at position (240, 201, 62x62):\n",
      "  Dark model:  similarity=0.9019, threshold=0.8000\n",
      "  Light model: similarity=0.6951, threshold=0.8000\n",
      "  Best confidence: 0.9019, Status: RECOGNIZED\n",
      "Face 1 at position (122, 370, 62x62):\n",
      "  Dark model:  similarity=0.9109, threshold=0.8000\n",
      "  Light model: similarity=0.6657, threshold=0.8000\n",
      "  Best confidence: 0.9109, Status: RECOGNIZED\n",
      "Face 2 at position (250, 198, 62x62):\n",
      "  Dark model:  similarity=0.9008, threshold=0.8000\n",
      "  Light model: similarity=0.6958, threshold=0.8000\n",
      "  Best confidence: 0.9008, Status: RECOGNIZED\n",
      "Face 1 at position (121, 369, 62x62):\n",
      "  Dark model:  similarity=0.9043, threshold=0.8000\n",
      "  Light model: similarity=0.6643, threshold=0.8000\n",
      "  Best confidence: 0.9043, Status: RECOGNIZED\n",
      "Face 2 at position (260, 196, 62x62):\n",
      "  Dark model:  similarity=0.9025, threshold=0.8000\n",
      "  Light model: similarity=0.6949, threshold=0.8000\n",
      "  Best confidence: 0.9025, Status: RECOGNIZED\n",
      "Face 1 at position (121, 368, 62x62):\n",
      "  Dark model:  similarity=0.9041, threshold=0.8000\n",
      "  Light model: similarity=0.6654, threshold=0.8000\n",
      "  Best confidence: 0.9041, Status: RECOGNIZED\n",
      "Face 2 at position (270, 193, 62x62):\n",
      "  Dark model:  similarity=0.9016, threshold=0.8000\n",
      "  Light model: similarity=0.6939, threshold=0.8000\n",
      "  Best confidence: 0.9016, Status: RECOGNIZED\n",
      "Face 1 at position (121, 367, 62x62):\n",
      "  Dark model:  similarity=0.9042, threshold=0.8000\n",
      "  Light model: similarity=0.6634, threshold=0.8000\n",
      "  Best confidence: 0.9042, Status: RECOGNIZED\n",
      "Face 2 at position (281, 192, 62x62):\n",
      "  Dark model:  similarity=0.8997, threshold=0.8000\n",
      "  Light model: similarity=0.6974, threshold=0.8000\n",
      "  Best confidence: 0.8997, Status: RECOGNIZED\n",
      "Face 1 at position (121, 368, 62x62):\n",
      "  Dark model:  similarity=0.9043, threshold=0.8000\n",
      "  Light model: similarity=0.6643, threshold=0.8000\n",
      "  Best confidence: 0.9043, Status: RECOGNIZED\n",
      "Face 2 at position (292, 192, 62x62):\n",
      "  Dark model:  similarity=0.8978, threshold=0.8000\n",
      "  Light model: similarity=0.6997, threshold=0.8000\n",
      "  Best confidence: 0.8978, Status: RECOGNIZED\n",
      "Face 3 at position (119, 401, 62x62):\n",
      "  Dark model:  similarity=0.8634, threshold=0.8000\n",
      "  Light model: similarity=0.6428, threshold=0.8000\n",
      "  Best confidence: 0.8634, Status: RECOGNIZED\n",
      "Face 1 at position (121, 370, 62x62):\n",
      "  Dark model:  similarity=0.9063, threshold=0.8000\n",
      "  Light model: similarity=0.6650, threshold=0.8000\n",
      "  Best confidence: 0.9063, Status: RECOGNIZED\n",
      "Face 2 at position (302, 196, 62x62):\n",
      "  Dark model:  similarity=0.8961, threshold=0.8000\n",
      "  Light model: similarity=0.6999, threshold=0.8000\n",
      "  Best confidence: 0.8961, Status: RECOGNIZED\n",
      "Face 1 at position (121, 370, 62x62):\n",
      "  Dark model:  similarity=0.9076, threshold=0.8000\n",
      "  Light model: similarity=0.6642, threshold=0.8000\n",
      "  Best confidence: 0.9076, Status: RECOGNIZED\n",
      "Face 2 at position (311, 201, 62x62):\n",
      "  Dark model:  similarity=0.8962, threshold=0.8000\n",
      "  Light model: similarity=0.6985, threshold=0.8000\n",
      "  Best confidence: 0.8962, Status: RECOGNIZED\n",
      "Face 3 at position (119, 403, 62x62):\n",
      "  Dark model:  similarity=0.8654, threshold=0.8000\n",
      "  Light model: similarity=0.6434, threshold=0.8000\n",
      "  Best confidence: 0.8654, Status: RECOGNIZED\n",
      "Progress: 48.9% (90/184)\n",
      "Face 1 at position (121, 371, 62x62):\n",
      "  Dark model:  similarity=0.9096, threshold=0.8000\n",
      "  Light model: similarity=0.6654, threshold=0.8000\n",
      "  Best confidence: 0.9096, Status: RECOGNIZED\n",
      "Face 1 at position (121, 370, 62x62):\n",
      "  Dark model:  similarity=0.9081, threshold=0.8000\n",
      "  Light model: similarity=0.6640, threshold=0.8000\n",
      "  Best confidence: 0.9081, Status: RECOGNIZED\n",
      "Face 1 at position (121, 369, 62x62):\n",
      "  Dark model:  similarity=0.9067, threshold=0.8000\n",
      "  Light model: similarity=0.6642, threshold=0.8000\n",
      "  Best confidence: 0.9067, Status: RECOGNIZED\n",
      "Face 2 at position (530, 464, 76x76):\n",
      "  Dark model:  similarity=0.7181, threshold=0.8000\n",
      "  Light model: similarity=0.7322, threshold=0.8000\n",
      "  Best confidence: 0.7322, Status: UNKNOWN\n",
      "Face 1 at position (121, 368, 62x62):\n",
      "  Dark model:  similarity=0.9048, threshold=0.8000\n",
      "  Light model: similarity=0.6640, threshold=0.8000\n",
      "  Best confidence: 0.9048, Status: RECOGNIZED\n",
      "Face 2 at position (534, 466, 76x76):\n",
      "  Dark model:  similarity=0.7520, threshold=0.8000\n",
      "  Light model: similarity=0.7249, threshold=0.8000\n",
      "  Best confidence: 0.7520, Status: UNKNOWN\n",
      "Face 1 at position (121, 368, 62x62):\n",
      "  Dark model:  similarity=0.9048, threshold=0.8000\n",
      "  Light model: similarity=0.6633, threshold=0.8000\n",
      "  Best confidence: 0.9048, Status: RECOGNIZED\n",
      "Face 1 at position (121, 369, 62x62):\n",
      "  Dark model:  similarity=0.9037, threshold=0.8000\n",
      "  Light model: similarity=0.6656, threshold=0.8000\n",
      "  Best confidence: 0.9037, Status: RECOGNIZED\n",
      "Face 1 at position (121, 370, 62x62):\n",
      "  Dark model:  similarity=0.9038, threshold=0.8000\n",
      "  Light model: similarity=0.6656, threshold=0.8000\n",
      "  Best confidence: 0.9038, Status: RECOGNIZED\n",
      "Face 1 at position (121, 370, 62x62):\n",
      "  Dark model:  similarity=0.9035, threshold=0.8000\n",
      "  Light model: similarity=0.6644, threshold=0.8000\n",
      "  Best confidence: 0.9035, Status: RECOGNIZED\n",
      "Face 1 at position (121, 370, 62x62):\n",
      "  Dark model:  similarity=0.9045, threshold=0.8000\n",
      "  Light model: similarity=0.6639, threshold=0.8000\n",
      "  Best confidence: 0.9045, Status: RECOGNIZED\n",
      "Face 1 at position (121, 370, 62x62):\n",
      "  Dark model:  similarity=0.9036, threshold=0.8000\n",
      "  Light model: similarity=0.6658, threshold=0.8000\n",
      "  Best confidence: 0.9036, Status: RECOGNIZED\n",
      "Face 1 at position (121, 368, 62x62):\n",
      "  Dark model:  similarity=0.9036, threshold=0.8000\n",
      "  Light model: similarity=0.6632, threshold=0.8000\n",
      "  Best confidence: 0.9036, Status: RECOGNIZED\n",
      "Face 1 at position (121, 368, 62x62):\n",
      "  Dark model:  similarity=0.9070, threshold=0.8000\n",
      "  Light model: similarity=0.6642, threshold=0.8000\n",
      "  Best confidence: 0.9070, Status: RECOGNIZED\n",
      "Face 1 at position (121, 368, 62x62):\n",
      "  Dark model:  similarity=0.9105, threshold=0.8000\n",
      "  Light model: similarity=0.6652, threshold=0.8000\n",
      "  Best confidence: 0.9105, Status: RECOGNIZED\n",
      "Face 1 at position (121, 369, 62x62):\n",
      "  Dark model:  similarity=0.9099, threshold=0.8000\n",
      "  Light model: similarity=0.6657, threshold=0.8000\n",
      "  Best confidence: 0.9099, Status: RECOGNIZED\n",
      "Face 1 at position (121, 370, 62x62):\n",
      "  Dark model:  similarity=0.9070, threshold=0.8000\n",
      "  Light model: similarity=0.6666, threshold=0.8000\n",
      "  Best confidence: 0.9070, Status: RECOGNIZED\n",
      "Face 1 at position (121, 370, 62x62):\n",
      "  Dark model:  similarity=0.9062, threshold=0.8000\n",
      "  Light model: similarity=0.6653, threshold=0.8000\n",
      "  Best confidence: 0.9062, Status: RECOGNIZED\n",
      "Face 1 at position (121, 370, 62x62):\n",
      "  Dark model:  similarity=0.9091, threshold=0.8000\n",
      "  Light model: similarity=0.6653, threshold=0.8000\n",
      "  Best confidence: 0.9091, Status: RECOGNIZED\n",
      "Face 1 at position (121, 370, 62x62):\n",
      "  Dark model:  similarity=0.9075, threshold=0.8000\n",
      "  Light model: similarity=0.6644, threshold=0.8000\n",
      "  Best confidence: 0.9075, Status: RECOGNIZED\n",
      "Face 1 at position (121, 369, 62x62):\n",
      "  Dark model:  similarity=0.9041, threshold=0.8000\n",
      "  Light model: similarity=0.6645, threshold=0.8000\n",
      "  Best confidence: 0.9041, Status: RECOGNIZED\n",
      "Face 1 at position (121, 369, 62x62):\n",
      "  Dark model:  similarity=0.9037, threshold=0.8000\n",
      "  Light model: similarity=0.6650, threshold=0.8000\n",
      "  Best confidence: 0.9037, Status: RECOGNIZED\n",
      "Face 1 at position (121, 368, 62x62):\n",
      "  Dark model:  similarity=0.9033, threshold=0.8000\n",
      "  Light model: similarity=0.6643, threshold=0.8000\n",
      "  Best confidence: 0.9033, Status: RECOGNIZED\n",
      "Face 1 at position (121, 369, 62x62):\n",
      "  Dark model:  similarity=0.9044, threshold=0.8000\n",
      "  Light model: similarity=0.6651, threshold=0.8000\n",
      "  Best confidence: 0.9044, Status: RECOGNIZED\n",
      "Face 1 at position (121, 370, 62x62):\n",
      "  Dark model:  similarity=0.9039, threshold=0.8000\n",
      "  Light model: similarity=0.6658, threshold=0.8000\n",
      "  Best confidence: 0.9039, Status: RECOGNIZED\n",
      "Face 1 at position (121, 370, 62x62):\n",
      "  Dark model:  similarity=0.9032, threshold=0.8000\n",
      "  Light model: similarity=0.6655, threshold=0.8000\n",
      "  Best confidence: 0.9032, Status: RECOGNIZED\n",
      "Face 1 at position (121, 370, 62x62):\n",
      "  Dark model:  similarity=0.9031, threshold=0.8000\n",
      "  Light model: similarity=0.6644, threshold=0.8000\n",
      "  Best confidence: 0.9031, Status: RECOGNIZED\n",
      "Face 1 at position (121, 370, 62x62):\n",
      "  Dark model:  similarity=0.9040, threshold=0.8000\n",
      "  Light model: similarity=0.6642, threshold=0.8000\n",
      "  Best confidence: 0.9040, Status: RECOGNIZED\n",
      "Face 1 at position (121, 370, 62x62):\n",
      "  Dark model:  similarity=0.9049, threshold=0.8000\n",
      "  Light model: similarity=0.6646, threshold=0.8000\n",
      "  Best confidence: 0.9049, Status: RECOGNIZED\n",
      "Face 1 at position (122, 368, 62x62):\n",
      "  Dark model:  similarity=0.9103, threshold=0.8000\n",
      "  Light model: similarity=0.6659, threshold=0.8000\n",
      "  Best confidence: 0.9103, Status: RECOGNIZED\n",
      "Face 1 at position (122, 368, 62x62):\n",
      "  Dark model:  similarity=0.9089, threshold=0.8000\n",
      "  Light model: similarity=0.6641, threshold=0.8000\n",
      "  Best confidence: 0.9089, Status: RECOGNIZED\n",
      "Face 1 at position (122, 369, 62x62):\n",
      "  Dark model:  similarity=0.9072, threshold=0.8000\n",
      "  Light model: similarity=0.6643, threshold=0.8000\n",
      "  Best confidence: 0.9072, Status: RECOGNIZED\n",
      "Progress: 65.2% (120/184)\n",
      "Face 1 at position (122, 370, 62x62):\n",
      "  Dark model:  similarity=0.9045, threshold=0.8000\n",
      "  Light model: similarity=0.6628, threshold=0.8000\n",
      "  Best confidence: 0.9045, Status: RECOGNIZED\n",
      "Face 1 at position (122, 370, 62x62):\n",
      "  Dark model:  similarity=0.9049, threshold=0.8000\n",
      "  Light model: similarity=0.6625, threshold=0.8000\n",
      "  Best confidence: 0.9049, Status: RECOGNIZED\n",
      "Face 1 at position (123, 370, 62x62):\n",
      "  Dark model:  similarity=0.9150, threshold=0.8000\n",
      "  Light model: similarity=0.6705, threshold=0.8000\n",
      "  Best confidence: 0.9150, Status: RECOGNIZED\n",
      "Face 1 at position (123, 370, 62x62):\n",
      "  Dark model:  similarity=0.9133, threshold=0.8000\n",
      "  Light model: similarity=0.6690, threshold=0.8000\n",
      "  Best confidence: 0.9133, Status: RECOGNIZED\n",
      "Face 1 at position (123, 370, 62x62):\n",
      "  Dark model:  similarity=0.9112, threshold=0.8000\n",
      "  Light model: similarity=0.6658, threshold=0.8000\n",
      "  Best confidence: 0.9112, Status: RECOGNIZED\n",
      "Face 1 at position (123, 369, 62x62):\n",
      "  Dark model:  similarity=0.9057, threshold=0.8000\n",
      "  Light model: similarity=0.6649, threshold=0.8000\n",
      "  Best confidence: 0.9057, Status: RECOGNIZED\n",
      "Face 1 at position (123, 369, 62x62):\n",
      "  Dark model:  similarity=0.9033, threshold=0.8000\n",
      "  Light model: similarity=0.6653, threshold=0.8000\n",
      "  Best confidence: 0.9033, Status: RECOGNIZED\n",
      "Face 1 at position (123, 369, 62x62):\n",
      "  Dark model:  similarity=0.9032, threshold=0.8000\n",
      "  Light model: similarity=0.6651, threshold=0.8000\n",
      "  Best confidence: 0.9032, Status: RECOGNIZED\n",
      "Face 1 at position (123, 370, 62x62):\n",
      "  Dark model:  similarity=0.9036, threshold=0.8000\n",
      "  Light model: similarity=0.6663, threshold=0.8000\n",
      "  Best confidence: 0.9036, Status: RECOGNIZED\n",
      "Face 1 at position (123, 370, 62x62):\n",
      "  Dark model:  similarity=0.9038, threshold=0.8000\n",
      "  Light model: similarity=0.6648, threshold=0.8000\n",
      "  Best confidence: 0.9038, Status: RECOGNIZED\n",
      "Face 1 at position (123, 370, 62x62):\n",
      "  Dark model:  similarity=0.9038, threshold=0.8000\n",
      "  Light model: similarity=0.6648, threshold=0.8000\n",
      "  Best confidence: 0.9038, Status: RECOGNIZED\n",
      "Face 1 at position (123, 370, 62x62):\n",
      "  Dark model:  similarity=0.9035, threshold=0.8000\n",
      "  Light model: similarity=0.6654, threshold=0.8000\n",
      "  Best confidence: 0.9035, Status: RECOGNIZED\n",
      "Face 1 at position (123, 370, 62x62):\n",
      "  Dark model:  similarity=0.9066, threshold=0.8000\n",
      "  Light model: similarity=0.6638, threshold=0.8000\n",
      "  Best confidence: 0.9066, Status: RECOGNIZED\n",
      "Face 1 at position (123, 370, 62x62):\n",
      "  Dark model:  similarity=0.9126, threshold=0.8000\n",
      "  Light model: similarity=0.6678, threshold=0.8000\n",
      "  Best confidence: 0.9126, Status: RECOGNIZED\n",
      "Face 1 at position (122, 370, 62x62):\n",
      "  Dark model:  similarity=0.9038, threshold=0.8000\n",
      "  Light model: similarity=0.6646, threshold=0.8000\n",
      "  Best confidence: 0.9038, Status: RECOGNIZED\n",
      "Face 1 at position (122, 369, 62x62):\n",
      "  Dark model:  similarity=0.9035, threshold=0.8000\n",
      "  Light model: similarity=0.6644, threshold=0.8000\n",
      "  Best confidence: 0.9035, Status: RECOGNIZED\n",
      "Face 1 at position (122, 368, 62x62):\n",
      "  Dark model:  similarity=0.9072, threshold=0.8000\n",
      "  Light model: similarity=0.6633, threshold=0.8000\n",
      "  Best confidence: 0.9072, Status: RECOGNIZED\n",
      "Face 1 at position (122, 368, 62x62):\n",
      "  Dark model:  similarity=0.9100, threshold=0.8000\n",
      "  Light model: similarity=0.6641, threshold=0.8000\n",
      "  Best confidence: 0.9100, Status: RECOGNIZED\n",
      "Face 1 at position (122, 370, 62x62):\n",
      "  Dark model:  similarity=0.9113, threshold=0.8000\n",
      "  Light model: similarity=0.6654, threshold=0.8000\n",
      "  Best confidence: 0.9113, Status: RECOGNIZED\n",
      "Face 1 at position (121, 371, 62x62):\n",
      "  Dark model:  similarity=0.9041, threshold=0.8000\n",
      "  Light model: similarity=0.6647, threshold=0.8000\n",
      "  Best confidence: 0.9041, Status: RECOGNIZED\n",
      "Face 1 at position (121, 371, 62x62):\n",
      "  Dark model:  similarity=0.9037, threshold=0.8000\n",
      "  Light model: similarity=0.6656, threshold=0.8000\n",
      "  Best confidence: 0.9037, Status: RECOGNIZED\n",
      "Face 1 at position (121, 370, 62x62):\n",
      "  Dark model:  similarity=0.9028, threshold=0.8000\n",
      "  Light model: similarity=0.6651, threshold=0.8000\n",
      "  Best confidence: 0.9028, Status: RECOGNIZED\n",
      "Face 1 at position (121, 369, 62x62):\n",
      "  Dark model:  similarity=0.9039, threshold=0.8000\n",
      "  Light model: similarity=0.6648, threshold=0.8000\n",
      "  Best confidence: 0.9039, Status: RECOGNIZED\n",
      "Face 1 at position (121, 368, 62x62):\n",
      "  Dark model:  similarity=0.9039, threshold=0.8000\n",
      "  Light model: similarity=0.6642, threshold=0.8000\n",
      "  Best confidence: 0.9039, Status: RECOGNIZED\n",
      "Face 1 at position (121, 368, 62x62):\n",
      "  Dark model:  similarity=0.9040, threshold=0.8000\n",
      "  Light model: similarity=0.6645, threshold=0.8000\n",
      "  Best confidence: 0.9040, Status: RECOGNIZED\n",
      "Face 1 at position (121, 369, 62x62):\n",
      "  Dark model:  similarity=0.9038, threshold=0.8000\n",
      "  Light model: similarity=0.6650, threshold=0.8000\n",
      "  Best confidence: 0.9038, Status: RECOGNIZED\n",
      "Face 1 at position (121, 370, 62x62):\n",
      "  Dark model:  similarity=0.9024, threshold=0.8000\n",
      "  Light model: similarity=0.6649, threshold=0.8000\n",
      "  Best confidence: 0.9024, Status: RECOGNIZED\n",
      "Face 1 at position (121, 371, 62x62):\n",
      "  Dark model:  similarity=0.9018, threshold=0.8000\n",
      "  Light model: similarity=0.6648, threshold=0.8000\n",
      "  Best confidence: 0.9018, Status: RECOGNIZED\n",
      "Face 1 at position (121, 371, 62x62):\n",
      "  Dark model:  similarity=0.9030, threshold=0.8000\n",
      "  Light model: similarity=0.6649, threshold=0.8000\n",
      "  Best confidence: 0.9030, Status: RECOGNIZED\n",
      "Face 1 at position (121, 370, 62x62):\n",
      "  Dark model:  similarity=0.9032, threshold=0.8000\n",
      "  Light model: similarity=0.6641, threshold=0.8000\n",
      "  Best confidence: 0.9032, Status: RECOGNIZED\n",
      "Progress: 81.5% (150/184)\n",
      "Face 1 at position (122, 368, 62x62):\n",
      "  Dark model:  similarity=0.9108, threshold=0.8000\n",
      "  Light model: similarity=0.6662, threshold=0.8000\n",
      "  Best confidence: 0.9108, Status: RECOGNIZED\n",
      "Face 1 at position (122, 368, 62x62):\n",
      "  Dark model:  similarity=0.9118, threshold=0.8000\n",
      "  Light model: similarity=0.6671, threshold=0.8000\n",
      "  Best confidence: 0.9118, Status: RECOGNIZED\n",
      "Face 1 at position (122, 368, 62x62):\n",
      "  Dark model:  similarity=0.9107, threshold=0.8000\n",
      "  Light model: similarity=0.6643, threshold=0.8000\n",
      "  Best confidence: 0.9107, Status: RECOGNIZED\n",
      "Face 1 at position (122, 370, 62x62):\n",
      "  Dark model:  similarity=0.9080, threshold=0.8000\n",
      "  Light model: similarity=0.6639, threshold=0.8000\n",
      "  Best confidence: 0.9080, Status: RECOGNIZED\n",
      "Face 1 at position (122, 370, 62x62):\n",
      "  Dark model:  similarity=0.9058, threshold=0.8000\n",
      "  Light model: similarity=0.6645, threshold=0.8000\n",
      "  Best confidence: 0.9058, Status: RECOGNIZED\n",
      "Face 1 at position (122, 370, 62x62):\n",
      "  Dark model:  similarity=0.9035, threshold=0.8000\n",
      "  Light model: similarity=0.6647, threshold=0.8000\n",
      "  Best confidence: 0.9035, Status: RECOGNIZED\n",
      "Face 1 at position (123, 370, 62x62):\n",
      "  Dark model:  similarity=0.9174, threshold=0.8000\n",
      "  Light model: similarity=0.6723, threshold=0.8000\n",
      "  Best confidence: 0.9174, Status: RECOGNIZED\n",
      "Face 1 at position (123, 370, 62x62):\n",
      "  Dark model:  similarity=0.9176, threshold=0.8000\n",
      "  Light model: similarity=0.6733, threshold=0.8000\n",
      "  Best confidence: 0.9176, Status: RECOGNIZED\n",
      "Face 1 at position (123, 369, 62x62):\n",
      "  Dark model:  similarity=0.9167, threshold=0.8000\n",
      "  Light model: similarity=0.6714, threshold=0.8000\n",
      "  Best confidence: 0.9167, Status: RECOGNIZED\n",
      "Face 1 at position (123, 368, 62x62):\n",
      "  Dark model:  similarity=0.9139, threshold=0.8000\n",
      "  Light model: similarity=0.6683, threshold=0.8000\n",
      "  Best confidence: 0.9139, Status: RECOGNIZED\n",
      "Face 1 at position (123, 368, 62x62):\n",
      "  Dark model:  similarity=0.9115, threshold=0.8000\n",
      "  Light model: similarity=0.6666, threshold=0.8000\n",
      "  Best confidence: 0.9115, Status: RECOGNIZED\n",
      "Face 1 at position (123, 370, 62x62):\n",
      "  Dark model:  similarity=0.9118, threshold=0.8000\n",
      "  Light model: similarity=0.6667, threshold=0.8000\n",
      "  Best confidence: 0.9118, Status: RECOGNIZED\n",
      "Face 1 at position (123, 370, 62x62):\n",
      "  Dark model:  similarity=0.9090, threshold=0.8000\n",
      "  Light model: similarity=0.6646, threshold=0.8000\n",
      "  Best confidence: 0.9090, Status: RECOGNIZED\n",
      "Face 1 at position (123, 370, 62x62):\n",
      "  Dark model:  similarity=0.9040, threshold=0.8000\n",
      "  Light model: similarity=0.6648, threshold=0.8000\n",
      "  Best confidence: 0.9040, Status: RECOGNIZED\n",
      "Face 2 at position (327, 201, 62x62):\n",
      "  Dark model:  similarity=0.8948, threshold=0.8000\n",
      "  Light model: similarity=0.6989, threshold=0.8000\n",
      "  Best confidence: 0.8948, Status: RECOGNIZED\n",
      "Face 1 at position (123, 370, 62x62):\n",
      "  Dark model:  similarity=0.9021, threshold=0.8000\n",
      "  Light model: similarity=0.6654, threshold=0.8000\n",
      "  Best confidence: 0.9021, Status: RECOGNIZED\n",
      "Face 2 at position (325, 200, 62x62):\n",
      "  Dark model:  similarity=0.8947, threshold=0.8000\n",
      "  Light model: similarity=0.7026, threshold=0.8000\n",
      "  Best confidence: 0.8947, Status: RECOGNIZED\n",
      "Face 1 at position (123, 370, 62x62):\n",
      "  Dark model:  similarity=0.9031, threshold=0.8000\n",
      "  Light model: similarity=0.6657, threshold=0.8000\n",
      "  Best confidence: 0.9031, Status: RECOGNIZED\n",
      "Face 2 at position (322, 199, 62x62):\n",
      "  Dark model:  similarity=0.8974, threshold=0.8000\n",
      "  Light model: similarity=0.6994, threshold=0.8000\n",
      "  Best confidence: 0.8974, Status: RECOGNIZED\n",
      "Face 1 at position (123, 370, 62x62):\n",
      "  Dark model:  similarity=0.9060, threshold=0.8000\n",
      "  Light model: similarity=0.6657, threshold=0.8000\n",
      "  Best confidence: 0.9060, Status: RECOGNIZED\n",
      "Face 2 at position (320, 198, 62x62):\n",
      "  Dark model:  similarity=0.8983, threshold=0.8000\n",
      "  Light model: similarity=0.6971, threshold=0.8000\n",
      "  Best confidence: 0.8983, Status: RECOGNIZED\n",
      "Face 1 at position (123, 369, 62x62):\n",
      "  Dark model:  similarity=0.9047, threshold=0.8000\n",
      "  Light model: similarity=0.6638, threshold=0.8000\n",
      "  Best confidence: 0.9047, Status: RECOGNIZED\n",
      "Face 2 at position (320, 197, 62x62):\n",
      "  Dark model:  similarity=0.8974, threshold=0.8000\n",
      "  Light model: similarity=0.6993, threshold=0.8000\n",
      "  Best confidence: 0.8974, Status: RECOGNIZED\n",
      "Face 1 at position (123, 370, 62x62):\n",
      "  Dark model:  similarity=0.9098, threshold=0.8000\n",
      "  Light model: similarity=0.6650, threshold=0.8000\n",
      "  Best confidence: 0.9098, Status: RECOGNIZED\n",
      "Face 2 at position (320, 197, 62x62):\n",
      "  Dark model:  similarity=0.8976, threshold=0.8000\n",
      "  Light model: similarity=0.6984, threshold=0.8000\n",
      "  Best confidence: 0.8976, Status: RECOGNIZED\n",
      "Face 1 at position (123, 370, 62x62):\n",
      "  Dark model:  similarity=0.9130, threshold=0.8000\n",
      "  Light model: similarity=0.6672, threshold=0.8000\n",
      "  Best confidence: 0.9130, Status: RECOGNIZED\n",
      "Face 2 at position (321, 197, 62x62):\n",
      "  Dark model:  similarity=0.8968, threshold=0.8000\n",
      "  Light model: similarity=0.7001, threshold=0.8000\n",
      "  Best confidence: 0.8968, Status: RECOGNIZED\n",
      "Face 1 at position (123, 370, 62x62):\n",
      "  Dark model:  similarity=0.9137, threshold=0.8000\n",
      "  Light model: similarity=0.6689, threshold=0.8000\n",
      "  Best confidence: 0.9137, Status: RECOGNIZED\n",
      "Face 2 at position (323, 196, 62x62):\n",
      "  Dark model:  similarity=0.8956, threshold=0.8000\n",
      "  Light model: similarity=0.6996, threshold=0.8000\n",
      "  Best confidence: 0.8956, Status: RECOGNIZED\n",
      "Face 1 at position (123, 370, 62x62):\n",
      "  Dark model:  similarity=0.9136, threshold=0.8000\n",
      "  Light model: similarity=0.6697, threshold=0.8000\n",
      "  Best confidence: 0.9136, Status: RECOGNIZED\n",
      "Face 2 at position (325, 198, 62x62):\n",
      "  Dark model:  similarity=0.8968, threshold=0.8000\n",
      "  Light model: similarity=0.6983, threshold=0.8000\n",
      "  Best confidence: 0.8968, Status: RECOGNIZED\n",
      "Face 1 at position (123, 370, 62x62):\n",
      "  Dark model:  similarity=0.9168, threshold=0.8000\n",
      "  Light model: similarity=0.6728, threshold=0.8000\n",
      "  Best confidence: 0.9168, Status: RECOGNIZED\n",
      "Face 2 at position (328, 199, 62x62):\n",
      "  Dark model:  similarity=0.8961, threshold=0.8000\n",
      "  Light model: similarity=0.6993, threshold=0.8000\n",
      "  Best confidence: 0.8961, Status: RECOGNIZED\n",
      "Face 1 at position (122, 370, 62x62):\n",
      "  Dark model:  similarity=0.9044, threshold=0.8000\n",
      "  Light model: similarity=0.6636, threshold=0.8000\n",
      "  Best confidence: 0.9044, Status: RECOGNIZED\n",
      "Face 2 at position (331, 200, 62x62):\n",
      "  Dark model:  similarity=0.8970, threshold=0.8000\n",
      "  Light model: similarity=0.6986, threshold=0.8000\n",
      "  Best confidence: 0.8970, Status: RECOGNIZED\n",
      "Face 1 at position (122, 370, 62x62):\n",
      "  Dark model:  similarity=0.9048, threshold=0.8000\n",
      "  Light model: similarity=0.6639, threshold=0.8000\n",
      "  Best confidence: 0.9048, Status: RECOGNIZED\n",
      "Face 2 at position (335, 201, 62x62):\n",
      "  Dark model:  similarity=0.8965, threshold=0.8000\n",
      "  Light model: similarity=0.7014, threshold=0.8000\n",
      "  Best confidence: 0.8965, Status: RECOGNIZED\n",
      "Face 1 at position (122, 370, 62x62):\n",
      "  Dark model:  similarity=0.9041, threshold=0.8000\n",
      "  Light model: similarity=0.6641, threshold=0.8000\n",
      "  Best confidence: 0.9041, Status: RECOGNIZED\n",
      "Face 1 at position (122, 370, 62x62):\n",
      "  Dark model:  similarity=0.9039, threshold=0.8000\n",
      "  Light model: similarity=0.6646, threshold=0.8000\n",
      "  Best confidence: 0.9039, Status: RECOGNIZED\n",
      "Face 1 at position (122, 370, 62x62):\n",
      "  Dark model:  similarity=0.9050, threshold=0.8000\n",
      "  Light model: similarity=0.6647, threshold=0.8000\n",
      "  Best confidence: 0.9050, Status: RECOGNIZED\n",
      "Face 1 at position (122, 370, 62x62):\n",
      "  Dark model:  similarity=0.9045, threshold=0.8000\n",
      "  Light model: similarity=0.6643, threshold=0.8000\n",
      "  Best confidence: 0.9045, Status: RECOGNIZED\n",
      "Face 1 at position (122, 370, 62x62):\n",
      "  Dark model:  similarity=0.9048, threshold=0.8000\n",
      "  Light model: similarity=0.6648, threshold=0.8000\n",
      "  Best confidence: 0.9048, Status: RECOGNIZED\n",
      "Progress: 97.8% (180/184)\n",
      "Face 1 at position (122, 370, 62x62):\n",
      "  Dark model:  similarity=0.9045, threshold=0.8000\n",
      "  Light model: similarity=0.6651, threshold=0.8000\n",
      "  Best confidence: 0.9045, Status: RECOGNIZED\n",
      "Face 1 at position (122, 370, 62x62):\n",
      "  Dark model:  similarity=0.9051, threshold=0.8000\n",
      "  Light model: similarity=0.6652, threshold=0.8000\n",
      "  Best confidence: 0.9051, Status: RECOGNIZED\n",
      "Face 1 at position (122, 370, 62x62):\n",
      "  Dark model:  similarity=0.9054, threshold=0.8000\n",
      "  Light model: similarity=0.6648, threshold=0.8000\n",
      "  Best confidence: 0.9054, Status: RECOGNIZED\n",
      "Face 1 at position (122, 370, 62x62):\n",
      "  Dark model:  similarity=0.9038, threshold=0.8000\n",
      "  Light model: similarity=0.6651, threshold=0.8000\n",
      "  Best confidence: 0.9038, Status: RECOGNIZED\n",
      "\n",
      "=== Processing Complete ===\n",
      "Output video saved to: output\\recognized_template_test_20250820_043328.mp4\n",
      "Total frames processed: 184\n",
      "Total face detections: 255\n",
      "Recognized faces: 253\n",
      "Unknown faces: 2\n",
      "Recognition rate: 99.2%\n"
     ]
    }
   ],
   "source": [
    "input_video = \"C:\\\\Users\\\\Asus\\\\Desktop\\\\face_detection\\\\videos\\\\test.mp4\"\n",
    "output_dir = \"output\"\n",
    "# Create output directory\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "# Generate output video filename with timestamp\n",
    "timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "video_name = \"test\"\n",
    "output_video = os.path.join(output_dir, f\"recognized_template_{video_name}_{timestamp}.mp4\")\n",
    "\n",
    "# Check if input video exists\n",
    "if not os.path.exists(input_video):\n",
    "    raise FileNotFoundError(f\"Input video not found: {input_video}\")\n",
    "\n",
    "print(f\"Processing video file with template matching: {input_video}\")\n",
    "success = process_video(input_video, dark_model_file, light_model_file, output_video, \n",
    "                      similarity_threshold, template_threshold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "541b8cf9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Face Recognition Complete ===\n",
      "Input video: C:\\Users\\Asus\\Desktop\\face_detection\\videos\\test.mp4\n",
      "Output video: output\\recognized_template_test_20250820_043328.mp4\n"
     ]
    }
   ],
   "source": [
    "if success:\n",
    "    print(f\"\\n=== Face Recognition Complete ===\")\n",
    "    print(f\"Input video: {input_video}\")\n",
    "    print(f\"Output video: {output_video}\")\n",
    "else:\n",
    "    print(\"Face recognition failed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b047692c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
